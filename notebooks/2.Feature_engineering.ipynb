{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 10000)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "if sys.platform=='win32':\n",
    "    sys.path.insert(0,\".\\..\\src\")\n",
    "        \n",
    "elif sys.platform=='linux':\n",
    "    sys.path.insert(0,\"./../src\")\n",
    "\n",
    "from utils import utils_ml, parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.EA.ipynb  2.Feature_engineering.ipynb\n"
     ]
    }
   ],
   "source": [
    "if sys.platform=='win32':\n",
    "    !dir .\\\n",
    "        \n",
    "elif sys.platform=='linux':\n",
    "    !ls ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/caanpaip/Documents/GitHub/ML-anti-fraud/notebooks\n"
     ]
    }
   ],
   "source": [
    "## para saber en que directório uno se encuentra\n",
    "#\n",
    "if sys.platform=='win32':\n",
    "    !echo %cd%\n",
    "        \n",
    "elif sys.platform=='linux':\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform=='win32':\n",
    "    df = pd.read_csv('.\\..\\data\\dados.csv', sep=',', decimal=\".\")\n",
    "        \n",
    "elif sys.platform=='linux':\n",
    "    df = pd.read_csv('./../data/dados.csv', sep=',', decimal=\".\")\n",
    "\n",
    "\n",
    "## dropping column \"o\" becaise it has 78% missing. and this is a boolean columns\n",
    "# df.drop(\"o\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>fecha</th>\n",
       "      <th>monto</th>\n",
       "      <th>score</th>\n",
       "      <th>fraude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7685</td>\n",
       "      <td>94436.24</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>5</td>\n",
       "      <td>Máquininha Corta Barba Cabelo Peito Perna Pelo...</td>\n",
       "      <td>cat_8d714cd</td>\n",
       "      <td>0.883598</td>\n",
       "      <td>240.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-03-27 11:51:16</td>\n",
       "      <td>5.64</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>9258.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>0</td>\n",
       "      <td>Avental Descartavel Manga Longa  - 50 Un. Tnt ...</td>\n",
       "      <td>cat_64b574b</td>\n",
       "      <td>0.376019</td>\n",
       "      <td>4008.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-04-15 19:58:08</td>\n",
       "      <td>124.71</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7455</td>\n",
       "      <td>242549.09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>AR</td>\n",
       "      <td>23</td>\n",
       "      <td>Bicicleta Mountain Fire Bird Rodado 29 Alumini...</td>\n",
       "      <td>cat_e9110c5</td>\n",
       "      <td>0.516368</td>\n",
       "      <td>1779.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-03-25 18:13:38</td>\n",
       "      <td>339.32</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>18923.90</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.482385</td>\n",
       "      <td>18.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>23</td>\n",
       "      <td>Caneta Delineador Carimbo Olho Gatinho Longo 2...</td>\n",
       "      <td>cat_d06e653</td>\n",
       "      <td>0.154036</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020-04-16 16:03:10</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>5728.68</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>2</td>\n",
       "      <td>Resident Evil Operation Raccoon City Ps3</td>\n",
       "      <td>cat_6c4cfdc</td>\n",
       "      <td>0.855798</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-04-02 10:24:45</td>\n",
       "      <td>3.53</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>4</td>\n",
       "      <td>0.8191</td>\n",
       "      <td>21393.63</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>4</td>\n",
       "      <td>Aparelho Lipocavitação Ultrassônico + Gel Cond...</td>\n",
       "      <td>cat_a5b2091</td>\n",
       "      <td>0.808366</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-04-11 19:31:07</td>\n",
       "      <td>47.15</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>11.0</td>\n",
       "      <td>UY</td>\n",
       "      <td>20</td>\n",
       "      <td>Sellos De Goma Automaticos,  Personalizados.</td>\n",
       "      <td>cat_e39ab7e</td>\n",
       "      <td>0.989981</td>\n",
       "      <td>499.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020-03-11 20:21:35</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>19</td>\n",
       "      <td>Hélice 3 Pás Alumínio Rabeta 6.5 Hp Pesca Barc...</td>\n",
       "      <td>cat_ee6ecc8</td>\n",
       "      <td>0.763939</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020-03-11 19:36:07</td>\n",
       "      <td>5.97</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6067</td>\n",
       "      <td>152906.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.099175</td>\n",
       "      <td>133.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>3</td>\n",
       "      <td>Tela Display Lcd Galaxy J7 Neo J701 Com Brilho...</td>\n",
       "      <td>cat_237e2d0</td>\n",
       "      <td>0.382728</td>\n",
       "      <td>4373.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020-03-16 07:13:24</td>\n",
       "      <td>25.83</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7546</td>\n",
       "      <td>7924.69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>80.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>4</td>\n",
       "      <td>A Magia Divina Das Velas. O Livro Das Sete Cha...</td>\n",
       "      <td>cat_8ef7164</td>\n",
       "      <td>0.627020</td>\n",
       "      <td>3495.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-03-26 08:47:12</td>\n",
       "      <td>5.28</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        a       b          c     d         e      f   g   h                                                  i            j         k       l       m  n    o  p                fecha   monto  score  fraude\n",
       "0       4  0.7685   94436.24  20.0  0.444828    1.0  BR   5  Máquininha Corta Barba Cabelo Peito Perna Pelo...  cat_8d714cd  0.883598   240.0   102.0  1  NaN  N  2020-03-27 11:51:16    5.64     66       0\n",
       "1       4  0.7550    9258.50   1.0  0.000000   33.0  BR   0  Avental Descartavel Manga Longa  - 50 Un. Tnt ...  cat_64b574b  0.376019  4008.0     0.0  1    Y  N  2020-04-15 19:58:08  124.71     72       0\n",
       "2       4  0.7455  242549.09   3.0  0.000000   19.0  AR  23  Bicicleta Mountain Fire Bird Rodado 29 Alumini...  cat_e9110c5  0.516368  1779.0    77.0  1  NaN  N  2020-03-25 18:13:38  339.32     95       0\n",
       "3       4  0.7631   18923.90  50.0  0.482385   18.0  BR  23  Caneta Delineador Carimbo Olho Gatinho Longo 2...  cat_d06e653  0.154036  1704.0  1147.0  1  NaN  Y  2020-04-16 16:03:10    3.54      2       0\n",
       "4       2  0.7315    5728.68  15.0  0.000000    1.0  BR   2           Resident Evil Operation Raccoon City Ps3  cat_6c4cfdc  0.855798  1025.0   150.0  1  NaN  N  2020-04-02 10:24:45    3.53     76       0\n",
       "...    ..     ...        ...   ...       ...    ...  ..  ..                                                ...          ...       ...     ...     ... ..  ... ..                  ...     ...    ...     ...\n",
       "149995  4  0.8191   21393.63   7.0  0.000000    1.0  BR   4  Aparelho Lipocavitação Ultrassônico + Gel Cond...  cat_a5b2091  0.808366  2009.0   434.0  1  NaN  N  2020-04-11 19:31:07   47.15     95       0\n",
       "149996  4     NaN        NaN  24.0  0.384615   11.0  UY  20       Sellos De Goma Automaticos,  Personalizados.  cat_e39ab7e  0.989981   499.0   135.0  1  NaN  Y  2020-03-11 20:21:35    9.69      0       0\n",
       "149997  4     NaN        NaN   3.0  0.477778    1.0  BR  19  Hélice 3 Pás Alumínio Rabeta 6.5 Hp Pesca Barc...  cat_ee6ecc8  0.763939   127.0   127.0  1  NaN  Y  2020-03-11 19:36:07    5.97     15       0\n",
       "149998  4  0.6067  152906.86   1.0  0.099175  133.0  BR   3  Tela Display Lcd Galaxy J7 Neo J701 Com Brilho...  cat_237e2d0  0.382728  4373.0   123.0  1  NaN  Y  2020-03-16 07:13:24   25.83     59       0\n",
       "149999  4  0.7546    7924.69   1.0  0.477778   80.0  BR   4  A Magia Divina Das Velas. O Livro Das Sete Cha...  cat_8ef7164  0.627020  3495.0     0.0  1  NaN  N  2020-03-26 08:47:12    5.28     35       0\n",
       "\n",
       "[150000 rows x 20 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"a\":\"a_int\",\n",
    "                    \"p\":\"p_boolean\",\"n\":'n_boolean',\n",
    "                     \"k\":\"k_float\",\"e\":\"e_float\",\"h\":\"h_float\",\"l\":\"l_float\",\"f\":\"f_float\",\"m\":\"m_float\",\"m\":\"m_float\",\"b\":\"b_float\",\"c\":\"c_float\",\"d\":\"d_float\",\"o\":\"o_obj\",\n",
    "                     'i': 'produto','j':'categoria_produto','g':'pais'}\n",
    "       , inplace = True)\n",
    "\n",
    "## Transform categorical features\n",
    "df['n_boolean'] = df['n_boolean'].astype(\"category\")\n",
    "df['p_boolean'] = df['p_boolean'].astype(\"category\")\n",
    "\n",
    "\n",
    "## creating columns os date and hour\n",
    "df['data'] = df['fecha'].apply(lambda x: x[:10])\n",
    "df['hora'] = df['fecha'].apply(lambda x: x[10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WoE transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n_boolean',\n",
       " 'p_boolean',\n",
       " 'categoria_produto',\n",
       " 'o_obj',\n",
       " 'pais',\n",
       " 'a_int',\n",
       " 'b_float',\n",
       " 'c_float',\n",
       " 'd_float',\n",
       " 'e_float',\n",
       " 'f_float',\n",
       " 'h_float',\n",
       " 'k_float',\n",
       " 'l_float',\n",
       " 'm_float',\n",
       " 'monto']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_cols = utils_ml.list_subset_words( df.columns.tolist() , [\"bool\",\"cat\",'obj','pais'])\n",
    "numeric_cols = [x for x in df.columns.tolist() if df[x].dtype.name!=\"object\" and df[x].dtype.name!=\"category\" and x!=\"fraude\" ]\n",
    "\n",
    "features = cats_cols + numeric_cols\n",
    "## Tirando o score\n",
    "features = features[:-1]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df.copy()\n",
    "\n",
    "for variable in features:\n",
    "\n",
    "    label = \"fraude\"\n",
    "    dtype_ = 'categorical' if df[variable].dtype=='O' or df[variable].dtype=='category' else 'numerical'\n",
    "    monotonic = True\n",
    "    save_path_pkl = '.\\..\\src\\\\features\\\\'\n",
    "\n",
    "\n",
    "    df = utils_ml.encode_woe_var(df, variable, label, dtype_, monotonic = True, save_path_pkl = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n_boolean_bins',\n",
       " 'p_boolean_bins',\n",
       " 'categoria_produto_bins',\n",
       " 'o_obj_bins',\n",
       " 'pais_bins',\n",
       " 'a_int_bins',\n",
       " 'b_float_bins',\n",
       " 'c_float_bins',\n",
       " 'd_float_bins',\n",
       " 'e_float_bins',\n",
       " 'f_float_bins',\n",
       " 'h_float_bins',\n",
       " 'k_float_bins',\n",
       " 'l_float_bins',\n",
       " 'm_float_bins',\n",
       " 'monto_bins']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_bins_woe = utils_ml.list_subset_words( df.columns.tolist(), [\"bin\"])\n",
    "features_bins_woe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_bins_woe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_model = df[features_bins_woe + [\"fraude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = features_bins_woe\n",
    "df_2_model_dum = df_2_model.copy()\n",
    "\n",
    "for var in cat_vars:\n",
    "\n",
    "    cat_list='var'+'_'+var\n",
    "    cat_list = pd.get_dummies( df_2_model_dum[var] , prefix=var)\n",
    "    data_dum = df_2_model_dum.join(cat_list)\n",
    "    df_2_model_dum = data_dum\n",
    "\n",
    "\n",
    "data_vars = df_2_model_dum.columns.tolist()\n",
    "to_keep = [i for i in data_vars if i not in cat_vars]\n",
    "\n",
    "df_2_model_dum = df_2_model_dum[to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_2_model_dum.drop(['fraude'], axis=1)\n",
    "y = df_2_model_dum['fraude']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=0, stratify=y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.999999999999996"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)[0]/y.value_counts(normalize=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[CV] END ......................class_weight={0: 0.0, 1: 1.0}; total time=   4.6s\n",
      "[CV] END ......................class_weight={0: 0.0, 1: 1.0}; total time=   5.2s\n",
      "[CV] END ......................class_weight={0: 0.0, 1: 1.0}; total time=   5.4s\n",
      "[CV] END ......................class_weight={0: 0.0, 1: 1.0}; total time=   5.5s\n",
      "[CV] END ......................class_weight={0: 0.0, 1: 1.0}; total time=   6.4s\n",
      "[CV] END class_weight={0: 0.004974874371859297, 1: 0.9950251256281407}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.004974874371859297, 1: 0.9950251256281407}; total time=   8.5s\n",
      "[CV] END class_weight={0: 0.004974874371859297, 1: 0.9950251256281407}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.004974874371859297, 1: 0.9950251256281407}; total time=   7.7s\n",
      "[CV] END class_weight={0: 0.004974874371859297, 1: 0.9950251256281407}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.009949748743718593, 1: 0.9900502512562814}; total time=   8.3s\n",
      "[CV] END class_weight={0: 0.009949748743718593, 1: 0.9900502512562814}; total time=   9.2s\n",
      "[CV] END class_weight={0: 0.009949748743718593, 1: 0.9900502512562814}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.009949748743718593, 1: 0.9900502512562814}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.009949748743718593, 1: 0.9900502512562814}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.014924623115577889, 1: 0.9850753768844221}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.014924623115577889, 1: 0.9850753768844221}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.014924623115577889, 1: 0.9850753768844221}; total time=   7.6s\n",
      "[CV] END class_weight={0: 0.014924623115577889, 1: 0.9850753768844221}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.019899497487437186, 1: 0.9801005025125629}; total time=   8.3s\n",
      "[CV] END class_weight={0: 0.019899497487437186, 1: 0.9801005025125629}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.019899497487437186, 1: 0.9801005025125629}; total time=   8.5s\n",
      "[CV] END class_weight={0: 0.014924623115577889, 1: 0.9850753768844221}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.019899497487437186, 1: 0.9801005025125629}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.019899497487437186, 1: 0.9801005025125629}; total time=   8.2s\n",
      "[CV] END class_weight={0: 0.024874371859296484, 1: 0.9751256281407035}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.024874371859296484, 1: 0.9751256281407035}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.024874371859296484, 1: 0.9751256281407035}; total time=   7.7s\n",
      "[CV] END class_weight={0: 0.029849246231155778, 1: 0.9701507537688442}; total time=   8.8s\n",
      "[CV] END class_weight={0: 0.029849246231155778, 1: 0.9701507537688442}; total time=   8.2s\n",
      "[CV] END class_weight={0: 0.024874371859296484, 1: 0.9751256281407035}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.024874371859296484, 1: 0.9751256281407035}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.029849246231155778, 1: 0.9701507537688442}; total time=   8.7s\n",
      "[CV] END class_weight={0: 0.029849246231155778, 1: 0.9701507537688442}; total time=   7.6s\n",
      "[CV] END class_weight={0: 0.034824120603015075, 1: 0.9651758793969849}; total time=   7.6s\n",
      "[CV] END class_weight={0: 0.029849246231155778, 1: 0.9701507537688442}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.034824120603015075, 1: 0.9651758793969849}; total time=   8.5s\n",
      "[CV] END class_weight={0: 0.034824120603015075, 1: 0.9651758793969849}; total time=   8.1s\n",
      "[CV] END class_weight={0: 0.034824120603015075, 1: 0.9651758793969849}; total time=   8.3s\n",
      "[CV] END class_weight={0: 0.034824120603015075, 1: 0.9651758793969849}; total time=   8.8s\n",
      "[CV] END class_weight={0: 0.03979899497487437, 1: 0.9602010050251256}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.03979899497487437, 1: 0.9602010050251256}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.03979899497487437, 1: 0.9602010050251256}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.03979899497487437, 1: 0.9602010050251256}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.03979899497487437, 1: 0.9602010050251256}; total time=   7.4s\n",
      "[CV] END class_weight={0: 0.04477386934673367, 1: 0.9552261306532663}; total time=   8.2s\n",
      "[CV] END class_weight={0: 0.04477386934673367, 1: 0.9552261306532663}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.04477386934673367, 1: 0.9552261306532663}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.04477386934673367, 1: 0.9552261306532663}; total time=   8.3s\n",
      "[CV] END class_weight={0: 0.04477386934673367, 1: 0.9552261306532663}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.04974874371859297, 1: 0.950251256281407}; total time=   7.8s\n",
      "[CV] END class_weight={0: 0.04974874371859297, 1: 0.950251256281407}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.04974874371859297, 1: 0.950251256281407}; total time=   8.5s\n",
      "[CV] END class_weight={0: 0.04974874371859297, 1: 0.950251256281407}; total time=   7.9s\n",
      "[CV] END class_weight={0: 0.04974874371859297, 1: 0.950251256281407}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.054723618090452265, 1: 0.9452763819095478}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.054723618090452265, 1: 0.9452763819095478}; total time=   8.7s\n",
      "[CV] END class_weight={0: 0.054723618090452265, 1: 0.9452763819095478}; total time=   8.7s\n",
      "[CV] END class_weight={0: 0.054723618090452265, 1: 0.9452763819095478}; total time=   7.7s\n",
      "[CV] END class_weight={0: 0.054723618090452265, 1: 0.9452763819095478}; total time=   8.3s\n",
      "[CV] END class_weight={0: 0.059698492462311556, 1: 0.9403015075376885}; total time=   8.0s\n",
      "[CV] END class_weight={0: 0.059698492462311556, 1: 0.9403015075376885}; total time=   8.5s\n",
      "[CV] END class_weight={0: 0.059698492462311556, 1: 0.9403015075376885}; total time=   6.8s\n",
      "[CV] END class_weight={0: 0.059698492462311556, 1: 0.9403015075376885}; total time=   9.2s\n",
      "[CV] END class_weight={0: 0.059698492462311556, 1: 0.9403015075376885}; total time=   8.2s\n",
      "[CV] END class_weight={0: 0.06467336683417085, 1: 0.9353266331658292}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.06467336683417085, 1: 0.9353266331658292}; total time=   8.1s\n",
      "[CV] END class_weight={0: 0.06467336683417085, 1: 0.9353266331658292}; total time=   8.0s\n",
      "[CV] END class_weight={0: 0.06467336683417085, 1: 0.9353266331658292}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.06467336683417085, 1: 0.9353266331658292}; total time=   8.2s\n",
      "[CV] END class_weight={0: 0.06964824120603015, 1: 0.9303517587939698}; total time=   8.7s\n",
      "[CV] END class_weight={0: 0.06964824120603015, 1: 0.9303517587939698}; total time=   8.7s\n",
      "[CV] END class_weight={0: 0.06964824120603015, 1: 0.9303517587939698}; total time=   8.1s\n",
      "[CV] END class_weight={0: 0.07462311557788945, 1: 0.9253768844221105}; total time=   7.7s\n",
      "[CV] END class_weight={0: 0.06964824120603015, 1: 0.9303517587939698}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.06964824120603015, 1: 0.9303517587939698}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.07462311557788945, 1: 0.9253768844221105}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.07462311557788945, 1: 0.9253768844221105}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.07462311557788945, 1: 0.9253768844221105}; total time=   7.6s\n",
      "[CV] END class_weight={0: 0.07462311557788945, 1: 0.9253768844221105}; total time=   9.2s\n",
      "[CV] END class_weight={0: 0.07959798994974875, 1: 0.9204020100502512}; total time=   8.7s\n",
      "[CV] END class_weight={0: 0.07959798994974875, 1: 0.9204020100502512}; total time=   7.1s\n",
      "[CV] END class_weight={0: 0.07959798994974875, 1: 0.9204020100502512}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.07959798994974875, 1: 0.9204020100502512}; total time=   7.8s\n",
      "[CV] END class_weight={0: 0.07959798994974875, 1: 0.9204020100502512}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.08457286432160804, 1: 0.915427135678392}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.08457286432160804, 1: 0.915427135678392}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.08457286432160804, 1: 0.915427135678392}; total time=   8.2s\n",
      "[CV] END class_weight={0: 0.08457286432160804, 1: 0.915427135678392}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.08457286432160804, 1: 0.915427135678392}; total time=   8.0s\n",
      "[CV] END class_weight={0: 0.08954773869346734, 1: 0.9104522613065327}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.08954773869346734, 1: 0.9104522613065327}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.08954773869346734, 1: 0.9104522613065327}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.08954773869346734, 1: 0.9104522613065327}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.08954773869346734, 1: 0.9104522613065327}; total time=   9.2s\n",
      "[CV] END class_weight={0: 0.09452261306532664, 1: 0.9054773869346734}; total time=   8.1s\n",
      "[CV] END class_weight={0: 0.09452261306532664, 1: 0.9054773869346734}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.09452261306532664, 1: 0.9054773869346734}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.09452261306532664, 1: 0.9054773869346734}; total time=   7.5s\n",
      "[CV] END class_weight={0: 0.09452261306532664, 1: 0.9054773869346734}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.09949748743718594, 1: 0.9005025125628141}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.09949748743718594, 1: 0.9005025125628141}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.09949748743718594, 1: 0.9005025125628141}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.09949748743718594, 1: 0.9005025125628141}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.10447236180904523, 1: 0.8955276381909547}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.10447236180904523, 1: 0.8955276381909547}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.09949748743718594, 1: 0.9005025125628141}; total time=  10.1s\n",
      "[CV] END class_weight={0: 0.10447236180904523, 1: 0.8955276381909547}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.10447236180904523, 1: 0.8955276381909547}; total time=  10.1s\n",
      "[CV] END class_weight={0: 0.10447236180904523, 1: 0.8955276381909547}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.10944723618090453, 1: 0.8905527638190954}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.10944723618090453, 1: 0.8905527638190954}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.10944723618090453, 1: 0.8905527638190954}; total time=   8.3s\n",
      "[CV] END class_weight={0: 0.10944723618090453, 1: 0.8905527638190954}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.10944723618090453, 1: 0.8905527638190954}; total time=  12.7s\n",
      "[CV] END class_weight={0: 0.11442211055276383, 1: 0.8855778894472361}; total time=   7.8s\n",
      "[CV] END class_weight={0: 0.11442211055276383, 1: 0.8855778894472361}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.11442211055276383, 1: 0.8855778894472361}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.11442211055276383, 1: 0.8855778894472361}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.11442211055276383, 1: 0.8855778894472361}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.11939698492462311, 1: 0.8806030150753769}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.11939698492462311, 1: 0.8806030150753769}; total time=   7.6s\n",
      "[CV] END class_weight={0: 0.11939698492462311, 1: 0.8806030150753769}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.11939698492462311, 1: 0.8806030150753769}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.11939698492462311, 1: 0.8806030150753769}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.12437185929648241, 1: 0.8756281407035176}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.12437185929648241, 1: 0.8756281407035176}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.12437185929648241, 1: 0.8756281407035176}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.1293467336683417, 1: 0.8706532663316583}; total time=   7.9s\n",
      "[CV] END class_weight={0: 0.12437185929648241, 1: 0.8756281407035176}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.12437185929648241, 1: 0.8756281407035176}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.1293467336683417, 1: 0.8706532663316583}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.1293467336683417, 1: 0.8706532663316583}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.1293467336683417, 1: 0.8706532663316583}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.13432160804020102, 1: 0.865678391959799}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.13432160804020102, 1: 0.865678391959799}; total time=   8.8s\n",
      "[CV] END class_weight={0: 0.1293467336683417, 1: 0.8706532663316583}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.13432160804020102, 1: 0.865678391959799}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.13432160804020102, 1: 0.865678391959799}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.13432160804020102, 1: 0.865678391959799}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.1392964824120603, 1: 0.8607035175879397}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.1392964824120603, 1: 0.8607035175879397}; total time=   8.2s\n",
      "[CV] END class_weight={0: 0.1392964824120603, 1: 0.8607035175879397}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.1392964824120603, 1: 0.8607035175879397}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.1392964824120603, 1: 0.8607035175879397}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.1442713567839196, 1: 0.8557286432160804}; total time=   8.2s\n",
      "[CV] END class_weight={0: 0.1442713567839196, 1: 0.8557286432160804}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.1442713567839196, 1: 0.8557286432160804}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.1492462311557789, 1: 0.850753768844221}; total time=   7.8s\n",
      "[CV] END class_weight={0: 0.1442713567839196, 1: 0.8557286432160804}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.1492462311557789, 1: 0.850753768844221}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.1442713567839196, 1: 0.8557286432160804}; total time=  12.6s\n",
      "[CV] END class_weight={0: 0.1492462311557789, 1: 0.850753768844221}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.1492462311557789, 1: 0.850753768844221}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.1492462311557789, 1: 0.850753768844221}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.1542211055276382, 1: 0.8457788944723618}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.1542211055276382, 1: 0.8457788944723618}; total time=   9.2s\n",
      "[CV] END class_weight={0: 0.1542211055276382, 1: 0.8457788944723618}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.1542211055276382, 1: 0.8457788944723618}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.1542211055276382, 1: 0.8457788944723618}; total time=   9.2s\n",
      "[CV] END class_weight={0: 0.1591959798994975, 1: 0.8408040201005025}; total time=   8.1s\n",
      "[CV] END class_weight={0: 0.1591959798994975, 1: 0.8408040201005025}; total time=   7.8s\n",
      "[CV] END class_weight={0: 0.1591959798994975, 1: 0.8408040201005025}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.1591959798994975, 1: 0.8408040201005025}; total time=  10.1s\n",
      "[CV] END class_weight={0: 0.16417085427135678, 1: 0.8358291457286432}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.1591959798994975, 1: 0.8408040201005025}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.16417085427135678, 1: 0.8358291457286432}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.1691457286432161, 1: 0.8308542713567839}; total time=   8.5s\n",
      "[CV] END class_weight={0: 0.16417085427135678, 1: 0.8358291457286432}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.16417085427135678, 1: 0.8358291457286432}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.16417085427135678, 1: 0.8358291457286432}; total time=  13.1s\n",
      "[CV] END class_weight={0: 0.1691457286432161, 1: 0.8308542713567839}; total time=   8.2s\n",
      "[CV] END class_weight={0: 0.1691457286432161, 1: 0.8308542713567839}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.1691457286432161, 1: 0.8308542713567839}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.1691457286432161, 1: 0.8308542713567839}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.17412060301507537, 1: 0.8258793969849246}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.17412060301507537, 1: 0.8258793969849246}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.17412060301507537, 1: 0.8258793969849246}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.17412060301507537, 1: 0.8258793969849246}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.17412060301507537, 1: 0.8258793969849246}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.17909547738693468, 1: 0.8209045226130653}; total time=  10.1s\n",
      "[CV] END class_weight={0: 0.17909547738693468, 1: 0.8209045226130653}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.17909547738693468, 1: 0.8209045226130653}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.18407035175879397, 1: 0.8159296482412061}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.17909547738693468, 1: 0.8209045226130653}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.17909547738693468, 1: 0.8209045226130653}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.18407035175879397, 1: 0.8159296482412061}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.18407035175879397, 1: 0.8159296482412061}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.18407035175879397, 1: 0.8159296482412061}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.18407035175879397, 1: 0.8159296482412061}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.18904522613065328, 1: 0.8109547738693468}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.18904522613065328, 1: 0.8109547738693468}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.18904522613065328, 1: 0.8109547738693468}; total time=   9.2s\n",
      "[CV] END class_weight={0: 0.18904522613065328, 1: 0.8109547738693468}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.18904522613065328, 1: 0.8109547738693468}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.19402010050251256, 1: 0.8059798994974874}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.19402010050251256, 1: 0.8059798994974874}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.19402010050251256, 1: 0.8059798994974874}; total time=   9.2s\n",
      "[CV] END class_weight={0: 0.19402010050251256, 1: 0.8059798994974874}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.19899497487437187, 1: 0.8010050251256281}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.19402010050251256, 1: 0.8059798994974874}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.19899497487437187, 1: 0.8010050251256281}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.19899497487437187, 1: 0.8010050251256281}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.19899497487437187, 1: 0.8010050251256281}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.19899497487437187, 1: 0.8010050251256281}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.20396984924623116, 1: 0.7960301507537688}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.20396984924623116, 1: 0.7960301507537688}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.20396984924623116, 1: 0.7960301507537688}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.20396984924623116, 1: 0.7960301507537688}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.20396984924623116, 1: 0.7960301507537688}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.20894472361809047, 1: 0.7910552763819095}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.20894472361809047, 1: 0.7910552763819095}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.20894472361809047, 1: 0.7910552763819095}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.21391959798994975, 1: 0.7860804020100502}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.20894472361809047, 1: 0.7910552763819095}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.20894472361809047, 1: 0.7910552763819095}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.21391959798994975, 1: 0.7860804020100502}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.21391959798994975, 1: 0.7860804020100502}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.21391959798994975, 1: 0.7860804020100502}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.21391959798994975, 1: 0.7860804020100502}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.21889447236180906, 1: 0.781105527638191}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.21889447236180906, 1: 0.781105527638191}; total time=  10.1s\n",
      "[CV] END class_weight={0: 0.21889447236180906, 1: 0.781105527638191}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.22386934673366835, 1: 0.7761306532663317}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.22386934673366835, 1: 0.7761306532663317}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.21889447236180906, 1: 0.781105527638191}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.21889447236180906, 1: 0.781105527638191}; total time=  12.0s\n",
      "[CV] END class_weight={0: 0.22386934673366835, 1: 0.7761306532663317}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.22386934673366835, 1: 0.7761306532663317}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.22386934673366835, 1: 0.7761306532663317}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.22884422110552766, 1: 0.7711557788944723}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.22884422110552766, 1: 0.7711557788944723}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.22884422110552766, 1: 0.7711557788944723}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.22884422110552766, 1: 0.7711557788944723}; total time=  10.1s\n",
      "[CV] END class_weight={0: 0.22884422110552766, 1: 0.7711557788944723}; total time=  13.7s\n",
      "[CV] END class_weight={0: 0.23381909547738694, 1: 0.7661809045226131}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.23381909547738694, 1: 0.7661809045226131}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.23381909547738694, 1: 0.7661809045226131}; total time=   8.3s\n",
      "[CV] END class_weight={0: 0.23381909547738694, 1: 0.7661809045226131}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.23879396984924622, 1: 0.7612060301507537}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.23879396984924622, 1: 0.7612060301507537}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.23381909547738694, 1: 0.7661809045226131}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.23879396984924622, 1: 0.7612060301507537}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.23879396984924622, 1: 0.7612060301507537}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.23879396984924622, 1: 0.7612060301507537}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.24376884422110554, 1: 0.7562311557788944}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.24376884422110554, 1: 0.7562311557788944}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.24376884422110554, 1: 0.7562311557788944}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.24376884422110554, 1: 0.7562311557788944}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.24376884422110554, 1: 0.7562311557788944}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.24874371859296482, 1: 0.7512562814070352}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.24874371859296482, 1: 0.7512562814070352}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.24874371859296482, 1: 0.7512562814070352}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.24874371859296482, 1: 0.7512562814070352}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.24874371859296482, 1: 0.7512562814070352}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.25371859296482413, 1: 0.7462814070351759}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.25371859296482413, 1: 0.7462814070351759}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.25371859296482413, 1: 0.7462814070351759}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.25371859296482413, 1: 0.7462814070351759}; total time=   8.2s\n",
      "[CV] END class_weight={0: 0.25371859296482413, 1: 0.7462814070351759}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.2586934673366834, 1: 0.7413065326633166}; total time=   8.3s\n",
      "[CV] END class_weight={0: 0.2586934673366834, 1: 0.7413065326633166}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.2586934673366834, 1: 0.7413065326633166}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.2636683417085427, 1: 0.7363316582914573}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.2586934673366834, 1: 0.7413065326633166}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.2636683417085427, 1: 0.7363316582914573}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.2636683417085427, 1: 0.7363316582914573}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.2636683417085427, 1: 0.7363316582914573}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.2636683417085427, 1: 0.7363316582914573}; total time=  14.5s\n",
      "[CV] END class_weight={0: 0.26864321608040204, 1: 0.731356783919598}; total time=   8.8s\n",
      "[CV] END class_weight={0: 0.2586934673366834, 1: 0.7413065326633166}; total time=  18.0s\n",
      "[CV] END class_weight={0: 0.26864321608040204, 1: 0.731356783919598}; total time=  10.1s\n",
      "[CV] END class_weight={0: 0.26864321608040204, 1: 0.731356783919598}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.26864321608040204, 1: 0.731356783919598}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.26864321608040204, 1: 0.731356783919598}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.2736180904522613, 1: 0.7263819095477386}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.2736180904522613, 1: 0.7263819095477386}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.2736180904522613, 1: 0.7263819095477386}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.2736180904522613, 1: 0.7263819095477386}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.2736180904522613, 1: 0.7263819095477386}; total time=   9.2s\n",
      "[CV] END class_weight={0: 0.2785929648241206, 1: 0.7214070351758795}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.2785929648241206, 1: 0.7214070351758795}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.2785929648241206, 1: 0.7214070351758795}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.2785929648241206, 1: 0.7214070351758795}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.2785929648241206, 1: 0.7214070351758795}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.2835678391959799, 1: 0.7164321608040201}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.2835678391959799, 1: 0.7164321608040201}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.2835678391959799, 1: 0.7164321608040201}; total time=  13.8s\n",
      "[CV] END class_weight={0: 0.2835678391959799, 1: 0.7164321608040201}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.2835678391959799, 1: 0.7164321608040201}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.2885427135678392, 1: 0.7114572864321608}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.2885427135678392, 1: 0.7114572864321608}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.2885427135678392, 1: 0.7114572864321608}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.2885427135678392, 1: 0.7114572864321608}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.2885427135678392, 1: 0.7114572864321608}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.2935175879396985, 1: 0.7064824120603015}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.2935175879396985, 1: 0.7064824120603015}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.2935175879396985, 1: 0.7064824120603015}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.2935175879396985, 1: 0.7064824120603015}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.2935175879396985, 1: 0.7064824120603015}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.2984924623115578, 1: 0.7015075376884422}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.2984924623115578, 1: 0.7015075376884422}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.2984924623115578, 1: 0.7015075376884422}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.2984924623115578, 1: 0.7015075376884422}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.2984924623115578, 1: 0.7015075376884422}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.3034673366834171, 1: 0.6965326633165829}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.3034673366834171, 1: 0.6965326633165829}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.3034673366834171, 1: 0.6965326633165829}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.3034673366834171, 1: 0.6965326633165829}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.3034673366834171, 1: 0.6965326633165829}; total time=  14.2s\n",
      "[CV] END class_weight={0: 0.3084422110552764, 1: 0.6915577889447235}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.3084422110552764, 1: 0.6915577889447235}; total time=  13.6s\n",
      "[CV] END class_weight={0: 0.3084422110552764, 1: 0.6915577889447235}; total time=  13.4s\n",
      "[CV] END class_weight={0: 0.3084422110552764, 1: 0.6915577889447235}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.3134170854271357, 1: 0.6865829145728644}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.3084422110552764, 1: 0.6915577889447235}; total time=  12.6s\n",
      "[CV] END class_weight={0: 0.3134170854271357, 1: 0.6865829145728644}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.3134170854271357, 1: 0.6865829145728644}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.3134170854271357, 1: 0.6865829145728644}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.318391959798995, 1: 0.681608040201005}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.3134170854271357, 1: 0.6865829145728644}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.318391959798995, 1: 0.681608040201005}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.318391959798995, 1: 0.681608040201005}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.318391959798995, 1: 0.681608040201005}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.318391959798995, 1: 0.681608040201005}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.32336683417085427, 1: 0.6766331658291458}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.32336683417085427, 1: 0.6766331658291458}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.32336683417085427, 1: 0.6766331658291458}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.32336683417085427, 1: 0.6766331658291458}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.32336683417085427, 1: 0.6766331658291458}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.32834170854271355, 1: 0.6716582914572864}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.32834170854271355, 1: 0.6716582914572864}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.32834170854271355, 1: 0.6716582914572864}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.32834170854271355, 1: 0.6716582914572864}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.32834170854271355, 1: 0.6716582914572864}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.3333165829145729, 1: 0.6666834170854271}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.3333165829145729, 1: 0.6666834170854271}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.3333165829145729, 1: 0.6666834170854271}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.3382914572864322, 1: 0.6617085427135678}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.3333165829145729, 1: 0.6666834170854271}; total time=  13.7s\n",
      "[CV] END class_weight={0: 0.3333165829145729, 1: 0.6666834170854271}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.3382914572864322, 1: 0.6617085427135678}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.3382914572864322, 1: 0.6617085427135678}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.3382914572864322, 1: 0.6617085427135678}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.34326633165829146, 1: 0.6567336683417085}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.34326633165829146, 1: 0.6567336683417085}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.3382914572864322, 1: 0.6617085427135678}; total time=  13.8s\n",
      "[CV] END class_weight={0: 0.34326633165829146, 1: 0.6567336683417085}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.34326633165829146, 1: 0.6567336683417085}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.34326633165829146, 1: 0.6567336683417085}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.34824120603015074, 1: 0.6517587939698493}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.34824120603015074, 1: 0.6517587939698493}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.34824120603015074, 1: 0.6517587939698493}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.34824120603015074, 1: 0.6517587939698493}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.34824120603015074, 1: 0.6517587939698493}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.3532160804020101, 1: 0.6467839195979899}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.3532160804020101, 1: 0.6467839195979899}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.3532160804020101, 1: 0.6467839195979899}; total time=  13.2s\n",
      "[CV] END class_weight={0: 0.3532160804020101, 1: 0.6467839195979899}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.35819095477386936, 1: 0.6418090452261307}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.3532160804020101, 1: 0.6467839195979899}; total time=  12.0s\n",
      "[CV] END class_weight={0: 0.35819095477386936, 1: 0.6418090452261307}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.35819095477386936, 1: 0.6418090452261307}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.35819095477386936, 1: 0.6418090452261307}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.35819095477386936, 1: 0.6418090452261307}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.36316582914572865, 1: 0.6368341708542713}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.36316582914572865, 1: 0.6368341708542713}; total time=  12.6s\n",
      "[CV] END class_weight={0: 0.36316582914572865, 1: 0.6368341708542713}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.36316582914572865, 1: 0.6368341708542713}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.36316582914572865, 1: 0.6368341708542713}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.36814070351758793, 1: 0.6318592964824121}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.36814070351758793, 1: 0.6318592964824121}; total time=  12.2s\n",
      "[CV] END class_weight={0: 0.36814070351758793, 1: 0.6318592964824121}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.36814070351758793, 1: 0.6318592964824121}; total time=  10.1s\n",
      "[CV] END class_weight={0: 0.36814070351758793, 1: 0.6318592964824121}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.37311557788944727, 1: 0.6268844221105527}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.37311557788944727, 1: 0.6268844221105527}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.37311557788944727, 1: 0.6268844221105527}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.37311557788944727, 1: 0.6268844221105527}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.37809045226130655, 1: 0.6219095477386934}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.37311557788944727, 1: 0.6268844221105527}; total time=  12.2s\n",
      "[CV] END class_weight={0: 0.37809045226130655, 1: 0.6219095477386934}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.37809045226130655, 1: 0.6219095477386934}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.37809045226130655, 1: 0.6219095477386934}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.37809045226130655, 1: 0.6219095477386934}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.38306532663316584, 1: 0.6169346733668342}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.38306532663316584, 1: 0.6169346733668342}; total time=  14.9s\n",
      "[CV] END class_weight={0: 0.38306532663316584, 1: 0.6169346733668342}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.38306532663316584, 1: 0.6169346733668342}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.38306532663316584, 1: 0.6169346733668342}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.3880402010050251, 1: 0.6119597989949749}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.3880402010050251, 1: 0.6119597989949749}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.3880402010050251, 1: 0.6119597989949749}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.3880402010050251, 1: 0.6119597989949749}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.3880402010050251, 1: 0.6119597989949749}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.39301507537688446, 1: 0.6069849246231156}; total time=  12.6s\n",
      "[CV] END class_weight={0: 0.39301507537688446, 1: 0.6069849246231156}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.39301507537688446, 1: 0.6069849246231156}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.39301507537688446, 1: 0.6069849246231156}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.39798994974874374, 1: 0.6020100502512562}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.39301507537688446, 1: 0.6069849246231156}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.39798994974874374, 1: 0.6020100502512562}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.39798994974874374, 1: 0.6020100502512562}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.39798994974874374, 1: 0.6020100502512562}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.402964824120603, 1: 0.597035175879397}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.39798994974874374, 1: 0.6020100502512562}; total time=  14.8s\n",
      "[CV] END class_weight={0: 0.402964824120603, 1: 0.597035175879397}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.402964824120603, 1: 0.597035175879397}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.402964824120603, 1: 0.597035175879397}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.402964824120603, 1: 0.597035175879397}; total time=  14.2s\n",
      "[CV] END class_weight={0: 0.4079396984924623, 1: 0.5920603015075376}; total time=  12.7s\n",
      "[CV] END class_weight={0: 0.4079396984924623, 1: 0.5920603015075376}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.4079396984924623, 1: 0.5920603015075376}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.4129145728643216, 1: 0.5870854271356785}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.4079396984924623, 1: 0.5920603015075376}; total time=  12.7s\n",
      "[CV] END class_weight={0: 0.4129145728643216, 1: 0.5870854271356785}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.4129145728643216, 1: 0.5870854271356785}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.4079396984924623, 1: 0.5920603015075376}; total time=  14.0s\n",
      "[CV] END class_weight={0: 0.4129145728643216, 1: 0.5870854271356785}; total time=  14.4s\n",
      "[CV] END class_weight={0: 0.4129145728643216, 1: 0.5870854271356785}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.41788944723618093, 1: 0.5821105527638191}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.41788944723618093, 1: 0.5821105527638191}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.41788944723618093, 1: 0.5821105527638191}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.41788944723618093, 1: 0.5821105527638191}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.41788944723618093, 1: 0.5821105527638191}; total time=  12.8s\n",
      "[CV] END class_weight={0: 0.4228643216080402, 1: 0.5771356783919598}; total time=  12.6s\n",
      "[CV] END class_weight={0: 0.4228643216080402, 1: 0.5771356783919598}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.4228643216080402, 1: 0.5771356783919598}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.4228643216080402, 1: 0.5771356783919598}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.4228643216080402, 1: 0.5771356783919598}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.4278391959798995, 1: 0.5721608040201005}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.4278391959798995, 1: 0.5721608040201005}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.4278391959798995, 1: 0.5721608040201005}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.4278391959798995, 1: 0.5721608040201005}; total time=  13.1s\n",
      "[CV] END class_weight={0: 0.4278391959798995, 1: 0.5721608040201005}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.4328140703517588, 1: 0.5671859296482412}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.4328140703517588, 1: 0.5671859296482412}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.4328140703517588, 1: 0.5671859296482412}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.4328140703517588, 1: 0.5671859296482412}; total time=  12.2s\n",
      "[CV] END class_weight={0: 0.4328140703517588, 1: 0.5671859296482412}; total time=  13.4s\n",
      "[CV] END class_weight={0: 0.4377889447236181, 1: 0.5622110552763819}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.4377889447236181, 1: 0.5622110552763819}; total time=  13.2s\n",
      "[CV] END class_weight={0: 0.4377889447236181, 1: 0.5622110552763819}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.4377889447236181, 1: 0.5622110552763819}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.4377889447236181, 1: 0.5622110552763819}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.4427638190954774, 1: 0.5572361809045225}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.4427638190954774, 1: 0.5572361809045225}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.4427638190954774, 1: 0.5572361809045225}; total time=  14.0s\n",
      "[CV] END class_weight={0: 0.4427638190954774, 1: 0.5572361809045225}; total time=  13.5s\n",
      "[CV] END class_weight={0: 0.4477386934673367, 1: 0.5522613065326634}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.4427638190954774, 1: 0.5572361809045225}; total time=  13.0s\n",
      "[CV] END class_weight={0: 0.4477386934673367, 1: 0.5522613065326634}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.4477386934673367, 1: 0.5522613065326634}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.4477386934673367, 1: 0.5522613065326634}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.4477386934673367, 1: 0.5522613065326634}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.452713567839196, 1: 0.547286432160804}; total time=  13.6s\n",
      "[CV] END class_weight={0: 0.452713567839196, 1: 0.547286432160804}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.452713567839196, 1: 0.547286432160804}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.452713567839196, 1: 0.547286432160804}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.452713567839196, 1: 0.547286432160804}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.4576884422110553, 1: 0.5423115577889447}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.4576884422110553, 1: 0.5423115577889447}; total time=  13.3s\n",
      "[CV] END class_weight={0: 0.4576884422110553, 1: 0.5423115577889447}; total time=  13.6s\n",
      "[CV] END class_weight={0: 0.4576884422110553, 1: 0.5423115577889447}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.4576884422110553, 1: 0.5423115577889447}; total time=  12.6s\n",
      "[CV] END class_weight={0: 0.4626633165829146, 1: 0.5373366834170854}; total time=  13.2s\n",
      "[CV] END class_weight={0: 0.4626633165829146, 1: 0.5373366834170854}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.4626633165829146, 1: 0.5373366834170854}; total time=  12.2s\n",
      "[CV] END class_weight={0: 0.4626633165829146, 1: 0.5373366834170854}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.4626633165829146, 1: 0.5373366834170854}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.4676381909547739, 1: 0.5323618090452261}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.4676381909547739, 1: 0.5323618090452261}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.4676381909547739, 1: 0.5323618090452261}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.4676381909547739, 1: 0.5323618090452261}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.4676381909547739, 1: 0.5323618090452261}; total time=  13.0s\n",
      "[CV] END class_weight={0: 0.47261306532663316, 1: 0.5273869346733668}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.47261306532663316, 1: 0.5273869346733668}; total time=  13.8s\n",
      "[CV] END class_weight={0: 0.47261306532663316, 1: 0.5273869346733668}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.47261306532663316, 1: 0.5273869346733668}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.47261306532663316, 1: 0.5273869346733668}; total time=  12.2s\n",
      "[CV] END class_weight={0: 0.47758793969849245, 1: 0.5224120603015076}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.47758793969849245, 1: 0.5224120603015076}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.47758793969849245, 1: 0.5224120603015076}; total time=  13.7s\n",
      "[CV] END class_weight={0: 0.47758793969849245, 1: 0.5224120603015076}; total time=  14.0s\n",
      "[CV] END class_weight={0: 0.47758793969849245, 1: 0.5224120603015076}; total time=  12.8s\n",
      "[CV] END class_weight={0: 0.4825628140703518, 1: 0.5174371859296483}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.4825628140703518, 1: 0.5174371859296483}; total time=  13.7s\n",
      "[CV] END class_weight={0: 0.4825628140703518, 1: 0.5174371859296483}; total time=  12.8s\n",
      "[CV] END class_weight={0: 0.4825628140703518, 1: 0.5174371859296483}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.4825628140703518, 1: 0.5174371859296483}; total time=  14.0s\n",
      "[CV] END class_weight={0: 0.48753768844221107, 1: 0.5124623115577889}; total time=  14.4s\n",
      "[CV] END class_weight={0: 0.48753768844221107, 1: 0.5124623115577889}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.48753768844221107, 1: 0.5124623115577889}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.48753768844221107, 1: 0.5124623115577889}; total time=  13.5s\n",
      "[CV] END class_weight={0: 0.48753768844221107, 1: 0.5124623115577889}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.49251256281407035, 1: 0.5074874371859297}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.49251256281407035, 1: 0.5074874371859297}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.49251256281407035, 1: 0.5074874371859297}; total time=  12.8s\n",
      "[CV] END class_weight={0: 0.49251256281407035, 1: 0.5074874371859297}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.49748743718592964, 1: 0.5025125628140703}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.49251256281407035, 1: 0.5074874371859297}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.49748743718592964, 1: 0.5025125628140703}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.49748743718592964, 1: 0.5025125628140703}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.49748743718592964, 1: 0.5025125628140703}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.49748743718592964, 1: 0.5025125628140703}; total time=  12.7s\n",
      "[CV] END class_weight={0: 0.502462311557789, 1: 0.497537688442211}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.502462311557789, 1: 0.497537688442211}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.502462311557789, 1: 0.497537688442211}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.502462311557789, 1: 0.497537688442211}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.502462311557789, 1: 0.497537688442211}; total time=  12.2s\n",
      "[CV] END class_weight={0: 0.5074371859296483, 1: 0.49256281407035174}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.5074371859296483, 1: 0.49256281407035174}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.5074371859296483, 1: 0.49256281407035174}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.5074371859296483, 1: 0.49256281407035174}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.5074371859296483, 1: 0.49256281407035174}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.5124120603015075, 1: 0.48758793969849246}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.5124120603015075, 1: 0.48758793969849246}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.5124120603015075, 1: 0.48758793969849246}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.5124120603015075, 1: 0.48758793969849246}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.5124120603015075, 1: 0.48758793969849246}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.5173869346733668, 1: 0.4826130653266332}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.5173869346733668, 1: 0.4826130653266332}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.5173869346733668, 1: 0.4826130653266332}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.5173869346733668, 1: 0.4826130653266332}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.5223618090452261, 1: 0.4776381909547739}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.5173869346733668, 1: 0.4826130653266332}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.5223618090452261, 1: 0.4776381909547739}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.5223618090452261, 1: 0.4776381909547739}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.5223618090452261, 1: 0.4776381909547739}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.5223618090452261, 1: 0.4776381909547739}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.5273366834170854, 1: 0.4726633165829146}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.5273366834170854, 1: 0.4726633165829146}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.5273366834170854, 1: 0.4726633165829146}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.5273366834170854, 1: 0.4726633165829146}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.5273366834170854, 1: 0.4726633165829146}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.5323115577889448, 1: 0.4676884422110552}; total time=  10.1s\n",
      "[CV] END class_weight={0: 0.5323115577889448, 1: 0.4676884422110552}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.5323115577889448, 1: 0.4676884422110552}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.5323115577889448, 1: 0.4676884422110552}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.5372864321608041, 1: 0.4627135678391959}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.5372864321608041, 1: 0.4627135678391959}; total time=  12.8s\n",
      "[CV] END class_weight={0: 0.5372864321608041, 1: 0.4627135678391959}; total time=  13.1s\n",
      "[CV] END class_weight={0: 0.5372864321608041, 1: 0.4627135678391959}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.5323115577889448, 1: 0.4676884422110552}; total time=  16.4s\n",
      "[CV] END class_weight={0: 0.5422613065326634, 1: 0.45773869346733664}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.5372864321608041, 1: 0.4627135678391959}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.5422613065326634, 1: 0.45773869346733664}; total time=  13.7s\n",
      "[CV] END class_weight={0: 0.5422613065326634, 1: 0.45773869346733664}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.5422613065326634, 1: 0.45773869346733664}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.5422613065326634, 1: 0.45773869346733664}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.5472361809045226, 1: 0.45276381909547736}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.5472361809045226, 1: 0.45276381909547736}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.5472361809045226, 1: 0.45276381909547736}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.5472361809045226, 1: 0.45276381909547736}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.5472361809045226, 1: 0.45276381909547736}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.5522110552763819, 1: 0.4477889447236181}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.5522110552763819, 1: 0.4477889447236181}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.5522110552763819, 1: 0.4477889447236181}; total time=  13.0s\n",
      "[CV] END class_weight={0: 0.5522110552763819, 1: 0.4477889447236181}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.5522110552763819, 1: 0.4477889447236181}; total time=  12.7s\n",
      "[CV] END class_weight={0: 0.5571859296482412, 1: 0.4428140703517588}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.5571859296482412, 1: 0.4428140703517588}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.5571859296482412, 1: 0.4428140703517588}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.5571859296482412, 1: 0.4428140703517588}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.5571859296482412, 1: 0.4428140703517588}; total time=  12.7s\n",
      "[CV] END class_weight={0: 0.5621608040201005, 1: 0.4378391959798995}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.5621608040201005, 1: 0.4378391959798995}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.5621608040201005, 1: 0.4378391959798995}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.5621608040201005, 1: 0.4378391959798995}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.5671356783919598, 1: 0.4328643216080402}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.5621608040201005, 1: 0.4378391959798995}; total time=  13.0s\n",
      "[CV] END class_weight={0: 0.5671356783919598, 1: 0.4328643216080402}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.5671356783919598, 1: 0.4328643216080402}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.5671356783919598, 1: 0.4328643216080402}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.5671356783919598, 1: 0.4328643216080402}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.5721105527638191, 1: 0.42788944723618094}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.5721105527638191, 1: 0.42788944723618094}; total time=  12.8s\n",
      "[CV] END class_weight={0: 0.5721105527638191, 1: 0.42788944723618094}; total time=  13.9s\n",
      "[CV] END class_weight={0: 0.5721105527638191, 1: 0.42788944723618094}; total time=  13.0s\n",
      "[CV] END class_weight={0: 0.5770854271356785, 1: 0.42291457286432155}; total time=   8.8s\n",
      "[CV] END class_weight={0: 0.5770854271356785, 1: 0.42291457286432155}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.5721105527638191, 1: 0.42788944723618094}; total time=  14.9s\n",
      "[CV] END class_weight={0: 0.5770854271356785, 1: 0.42291457286432155}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.5770854271356785, 1: 0.42291457286432155}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.5770854271356785, 1: 0.42291457286432155}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.5820603015075377, 1: 0.41793969849246226}; total time=  12.0s\n",
      "[CV] END class_weight={0: 0.5820603015075377, 1: 0.41793969849246226}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.5820603015075377, 1: 0.41793969849246226}; total time=  13.1s\n",
      "[CV] END class_weight={0: 0.5820603015075377, 1: 0.41793969849246226}; total time=  12.6s\n",
      "[CV] END class_weight={0: 0.5820603015075377, 1: 0.41793969849246226}; total time=  13.2s\n",
      "[CV] END class_weight={0: 0.587035175879397, 1: 0.412964824120603}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.587035175879397, 1: 0.412964824120603}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.587035175879397, 1: 0.412964824120603}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.587035175879397, 1: 0.412964824120603}; total time=  13.3s\n",
      "[CV] END class_weight={0: 0.587035175879397, 1: 0.412964824120603}; total time=  13.1s\n",
      "[CV] END class_weight={0: 0.5920100502512563, 1: 0.4079899497487437}; total time=  12.7s\n",
      "[CV] END class_weight={0: 0.5920100502512563, 1: 0.4079899497487437}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.5920100502512563, 1: 0.4079899497487437}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.5920100502512563, 1: 0.4079899497487437}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.5969849246231156, 1: 0.4030150753768844}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.5920100502512563, 1: 0.4079899497487437}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.5969849246231156, 1: 0.4030150753768844}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.5969849246231156, 1: 0.4030150753768844}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.5969849246231156, 1: 0.4030150753768844}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.5969849246231156, 1: 0.4030150753768844}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.6019597989949749, 1: 0.39804020100502513}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.6019597989949749, 1: 0.39804020100502513}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.6019597989949749, 1: 0.39804020100502513}; total time=  12.8s\n",
      "[CV] END class_weight={0: 0.6019597989949749, 1: 0.39804020100502513}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.6069346733668342, 1: 0.39306532663316585}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.6019597989949749, 1: 0.39804020100502513}; total time=  13.3s\n",
      "[CV] END class_weight={0: 0.6069346733668342, 1: 0.39306532663316585}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.6069346733668342, 1: 0.39306532663316585}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.6069346733668342, 1: 0.39306532663316585}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.6069346733668342, 1: 0.39306532663316585}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.6119095477386934, 1: 0.38809045226130656}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.6119095477386934, 1: 0.38809045226130656}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.6119095477386934, 1: 0.38809045226130656}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.6119095477386934, 1: 0.38809045226130656}; total time=  12.6s\n",
      "[CV] END class_weight={0: 0.6168844221105528, 1: 0.38311557788944717}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.6119095477386934, 1: 0.38809045226130656}; total time=  12.6s\n",
      "[CV] END class_weight={0: 0.6168844221105528, 1: 0.38311557788944717}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.6168844221105528, 1: 0.38311557788944717}; total time=  12.0s\n",
      "[CV] END class_weight={0: 0.6168844221105528, 1: 0.38311557788944717}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.6168844221105528, 1: 0.38311557788944717}; total time=  14.2s\n",
      "[CV] END class_weight={0: 0.6218592964824121, 1: 0.3781407035175879}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.6218592964824121, 1: 0.3781407035175879}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.6218592964824121, 1: 0.3781407035175879}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.6218592964824121, 1: 0.3781407035175879}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.6268341708542714, 1: 0.3731658291457286}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.6218592964824121, 1: 0.3781407035175879}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.6268341708542714, 1: 0.3731658291457286}; total time=  12.8s\n",
      "[CV] END class_weight={0: 0.6268341708542714, 1: 0.3731658291457286}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.6268341708542714, 1: 0.3731658291457286}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.6318090452261307, 1: 0.3681909547738693}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.6318090452261307, 1: 0.3681909547738693}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.6318090452261307, 1: 0.3681909547738693}; total time=   9.2s\n",
      "[CV] END class_weight={0: 0.6268341708542714, 1: 0.3731658291457286}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.6318090452261307, 1: 0.3681909547738693}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.6318090452261307, 1: 0.3681909547738693}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.63678391959799, 1: 0.36321608040201003}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.63678391959799, 1: 0.36321608040201003}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.63678391959799, 1: 0.36321608040201003}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.63678391959799, 1: 0.36321608040201003}; total time=  12.0s\n",
      "[CV] END class_weight={0: 0.63678391959799, 1: 0.36321608040201003}; total time=  12.7s\n",
      "[CV] END class_weight={0: 0.6417587939698493, 1: 0.35824120603015075}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.6417587939698493, 1: 0.35824120603015075}; total time=  13.1s\n",
      "[CV] END class_weight={0: 0.6417587939698493, 1: 0.35824120603015075}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.6417587939698493, 1: 0.35824120603015075}; total time=  12.6s\n",
      "[CV] END class_weight={0: 0.6417587939698493, 1: 0.35824120603015075}; total time=  12.8s\n",
      "[CV] END class_weight={0: 0.6467336683417085, 1: 0.35326633165829147}; total time=  12.2s\n",
      "[CV] END class_weight={0: 0.6467336683417085, 1: 0.35326633165829147}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.6467336683417085, 1: 0.35326633165829147}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.6467336683417085, 1: 0.35326633165829147}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.6467336683417085, 1: 0.35326633165829147}; total time=  13.6s\n",
      "[CV] END class_weight={0: 0.6517085427135678, 1: 0.3482914572864322}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.6517085427135678, 1: 0.3482914572864322}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.6517085427135678, 1: 0.3482914572864322}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.6517085427135678, 1: 0.3482914572864322}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.6517085427135678, 1: 0.3482914572864322}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.6566834170854271, 1: 0.3433165829145729}; total time=  13.0s\n",
      "[CV] END class_weight={0: 0.6566834170854271, 1: 0.3433165829145729}; total time=  12.7s\n",
      "[CV] END class_weight={0: 0.6566834170854271, 1: 0.3433165829145729}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.6566834170854271, 1: 0.3433165829145729}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.6566834170854271, 1: 0.3433165829145729}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.6616582914572865, 1: 0.3383417085427135}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.6616582914572865, 1: 0.3383417085427135}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.6616582914572865, 1: 0.3383417085427135}; total time=  13.3s\n",
      "[CV] END class_weight={0: 0.6616582914572865, 1: 0.3383417085427135}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.6616582914572865, 1: 0.3383417085427135}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.6666331658291458, 1: 0.3333668341708542}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.6666331658291458, 1: 0.3333668341708542}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.6666331658291458, 1: 0.3333668341708542}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.6666331658291458, 1: 0.3333668341708542}; total time=  12.6s\n",
      "[CV] END class_weight={0: 0.6666331658291458, 1: 0.3333668341708542}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.6716080402010051, 1: 0.32839195979899494}; total time=  13.2s\n",
      "[CV] END class_weight={0: 0.6716080402010051, 1: 0.32839195979899494}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.6716080402010051, 1: 0.32839195979899494}; total time=  13.4s\n",
      "[CV] END class_weight={0: 0.6716080402010051, 1: 0.32839195979899494}; total time=  13.2s\n",
      "[CV] END class_weight={0: 0.6716080402010051, 1: 0.32839195979899494}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.6765829145728643, 1: 0.32341708542713565}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.6765829145728643, 1: 0.32341708542713565}; total time=  13.5s\n",
      "[CV] END class_weight={0: 0.6765829145728643, 1: 0.32341708542713565}; total time=  13.2s\n",
      "[CV] END class_weight={0: 0.6765829145728643, 1: 0.32341708542713565}; total time=  12.7s\n",
      "[CV] END class_weight={0: 0.6765829145728643, 1: 0.32341708542713565}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.6815577889447236, 1: 0.31844221105527637}; total time=  13.4s\n",
      "[CV] END class_weight={0: 0.6815577889447236, 1: 0.31844221105527637}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.6815577889447236, 1: 0.31844221105527637}; total time=  12.8s\n",
      "[CV] END class_weight={0: 0.6815577889447236, 1: 0.31844221105527637}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.6865326633165829, 1: 0.3134673366834171}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.6815577889447236, 1: 0.31844221105527637}; total time=  14.7s\n",
      "[CV] END class_weight={0: 0.6915075376884422, 1: 0.3084924623115578}; total time=   8.1s\n",
      "[CV] END class_weight={0: 0.6865326633165829, 1: 0.3134673366834171}; total time=  12.8s\n",
      "[CV] END class_weight={0: 0.6865326633165829, 1: 0.3134673366834171}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.6865326633165829, 1: 0.3134673366834171}; total time=  14.7s\n",
      "[CV] END class_weight={0: 0.6865326633165829, 1: 0.3134673366834171}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.6915075376884422, 1: 0.3084924623115578}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.6915075376884422, 1: 0.3084924623115578}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.6915075376884422, 1: 0.3084924623115578}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.6964824120603015, 1: 0.3035175879396985}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.6964824120603015, 1: 0.3035175879396985}; total time=  13.1s\n",
      "[CV] END class_weight={0: 0.6964824120603015, 1: 0.3035175879396985}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.6964824120603015, 1: 0.3035175879396985}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.6915075376884422, 1: 0.3084924623115578}; total time=  15.1s\n",
      "[CV] END class_weight={0: 0.6964824120603015, 1: 0.3035175879396985}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.7014572864321609, 1: 0.2985427135678391}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.7014572864321609, 1: 0.2985427135678391}; total time=  12.0s\n",
      "[CV] END class_weight={0: 0.7014572864321609, 1: 0.2985427135678391}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.7014572864321609, 1: 0.2985427135678391}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.7014572864321609, 1: 0.2985427135678391}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.7064321608040202, 1: 0.29356783919597984}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.7064321608040202, 1: 0.29356783919597984}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.7064321608040202, 1: 0.29356783919597984}; total time=  13.1s\n",
      "[CV] END class_weight={0: 0.7064321608040202, 1: 0.29356783919597984}; total time=  12.2s\n",
      "[CV] END class_weight={0: 0.7064321608040202, 1: 0.29356783919597984}; total time=  13.0s\n",
      "[CV] END class_weight={0: 0.7114070351758794, 1: 0.28859296482412056}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.7114070351758794, 1: 0.28859296482412056}; total time=  13.0s\n",
      "[CV] END class_weight={0: 0.7114070351758794, 1: 0.28859296482412056}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.7114070351758794, 1: 0.28859296482412056}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.7114070351758794, 1: 0.28859296482412056}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.7163819095477387, 1: 0.2836180904522613}; total time=  14.6s\n",
      "[CV] END class_weight={0: 0.7163819095477387, 1: 0.2836180904522613}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.7163819095477387, 1: 0.2836180904522613}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.7163819095477387, 1: 0.2836180904522613}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.7163819095477387, 1: 0.2836180904522613}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.721356783919598, 1: 0.278643216080402}; total time=  13.0s\n",
      "[CV] END class_weight={0: 0.721356783919598, 1: 0.278643216080402}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.721356783919598, 1: 0.278643216080402}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.721356783919598, 1: 0.278643216080402}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.721356783919598, 1: 0.278643216080402}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.7263316582914573, 1: 0.2736683417085427}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.7263316582914573, 1: 0.2736683417085427}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.7263316582914573, 1: 0.2736683417085427}; total time=  13.9s\n",
      "[CV] END class_weight={0: 0.7263316582914573, 1: 0.2736683417085427}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.7313065326633166, 1: 0.2686934673366834}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.7263316582914573, 1: 0.2736683417085427}; total time=  12.6s\n",
      "[CV] END class_weight={0: 0.7313065326633166, 1: 0.2686934673366834}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.7313065326633166, 1: 0.2686934673366834}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.7313065326633166, 1: 0.2686934673366834}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.7313065326633166, 1: 0.2686934673366834}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.7362814070351759, 1: 0.26371859296482414}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.7362814070351759, 1: 0.26371859296482414}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.7362814070351759, 1: 0.26371859296482414}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.7362814070351759, 1: 0.26371859296482414}; total time=  12.2s\n",
      "[CV] END class_weight={0: 0.7362814070351759, 1: 0.26371859296482414}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.7412562814070351, 1: 0.25874371859296486}; total time=  12.0s\n",
      "[CV] END class_weight={0: 0.7412562814070351, 1: 0.25874371859296486}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.7412562814070351, 1: 0.25874371859296486}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.7462311557788945, 1: 0.25376884422110546}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.7412562814070351, 1: 0.25874371859296486}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.7462311557788945, 1: 0.25376884422110546}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.7412562814070351, 1: 0.25874371859296486}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.7462311557788945, 1: 0.25376884422110546}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.7462311557788945, 1: 0.25376884422110546}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.7462311557788945, 1: 0.25376884422110546}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.7512060301507538, 1: 0.24879396984924618}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.7512060301507538, 1: 0.24879396984924618}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.7512060301507538, 1: 0.24879396984924618}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.7512060301507538, 1: 0.24879396984924618}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.7512060301507538, 1: 0.24879396984924618}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.7561809045226131, 1: 0.2438190954773869}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.7561809045226131, 1: 0.2438190954773869}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.7561809045226131, 1: 0.2438190954773869}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.7561809045226131, 1: 0.2438190954773869}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.7611557788944724, 1: 0.2388442211055276}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.7561809045226131, 1: 0.2438190954773869}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.7611557788944724, 1: 0.2388442211055276}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.7611557788944724, 1: 0.2388442211055276}; total time=  13.1s\n",
      "[CV] END class_weight={0: 0.7611557788944724, 1: 0.2388442211055276}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.7611557788944724, 1: 0.2388442211055276}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.7661306532663317, 1: 0.23386934673366833}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.7661306532663317, 1: 0.23386934673366833}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.7661306532663317, 1: 0.23386934673366833}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.7661306532663317, 1: 0.23386934673366833}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.7661306532663317, 1: 0.23386934673366833}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.771105527638191, 1: 0.22889447236180904}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.771105527638191, 1: 0.22889447236180904}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.771105527638191, 1: 0.22889447236180904}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.771105527638191, 1: 0.22889447236180904}; total time=  13.2s\n",
      "[CV] END class_weight={0: 0.7760804020100502, 1: 0.22391959798994976}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.771105527638191, 1: 0.22889447236180904}; total time=  12.9s\n",
      "[CV] END class_weight={0: 0.7760804020100502, 1: 0.22391959798994976}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.7760804020100502, 1: 0.22391959798994976}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.7760804020100502, 1: 0.22391959798994976}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.7810552763819095, 1: 0.21894472361809048}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.7760804020100502, 1: 0.22391959798994976}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.7810552763819095, 1: 0.21894472361809048}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.7810552763819095, 1: 0.21894472361809048}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.7810552763819095, 1: 0.21894472361809048}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.7810552763819095, 1: 0.21894472361809048}; total time=  13.2s\n",
      "[CV] END class_weight={0: 0.7860301507537689, 1: 0.21396984924623108}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.7860301507537689, 1: 0.21396984924623108}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.7860301507537689, 1: 0.21396984924623108}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.7860301507537689, 1: 0.21396984924623108}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.7860301507537689, 1: 0.21396984924623108}; total time=  12.5s\n",
      "[CV] END class_weight={0: 0.7910050251256282, 1: 0.2089949748743718}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.7910050251256282, 1: 0.2089949748743718}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.7910050251256282, 1: 0.2089949748743718}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.7910050251256282, 1: 0.2089949748743718}; total time=  12.6s\n",
      "[CV] END class_weight={0: 0.7910050251256282, 1: 0.2089949748743718}; total time=  12.1s\n",
      "[CV] END class_weight={0: 0.7959798994974875, 1: 0.2040201005025125}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.7959798994974875, 1: 0.2040201005025125}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.7959798994974875, 1: 0.2040201005025125}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.7959798994974875, 1: 0.2040201005025125}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.7959798994974875, 1: 0.2040201005025125}; total time=  11.7s\n",
      "[CV] END class_weight={0: 0.8009547738693468, 1: 0.19904522613065323}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.8009547738693468, 1: 0.19904522613065323}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.8009547738693468, 1: 0.19904522613065323}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.8009547738693468, 1: 0.19904522613065323}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.805929648241206, 1: 0.19407035175879395}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.805929648241206, 1: 0.19407035175879395}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.8009547738693468, 1: 0.19904522613065323}; total time=  12.4s\n",
      "[CV] END class_weight={0: 0.805929648241206, 1: 0.19407035175879395}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.805929648241206, 1: 0.19407035175879395}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.805929648241206, 1: 0.19407035175879395}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.8109045226130653, 1: 0.18909547738693466}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.8109045226130653, 1: 0.18909547738693466}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.8109045226130653, 1: 0.18909547738693466}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.8109045226130653, 1: 0.18909547738693466}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.8109045226130653, 1: 0.18909547738693466}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.8158793969849246, 1: 0.18412060301507538}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.8158793969849246, 1: 0.18412060301507538}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.8158793969849246, 1: 0.18412060301507538}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.8158793969849246, 1: 0.18412060301507538}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.8158793969849246, 1: 0.18412060301507538}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.8208542713567839, 1: 0.1791457286432161}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.8208542713567839, 1: 0.1791457286432161}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.8208542713567839, 1: 0.1791457286432161}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.8208542713567839, 1: 0.1791457286432161}; total time=  11.8s\n",
      "[CV] END class_weight={0: 0.8258291457286432, 1: 0.1741708542713568}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.8208542713567839, 1: 0.1791457286432161}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.8258291457286432, 1: 0.1741708542713568}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.8258291457286432, 1: 0.1741708542713568}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.8258291457286432, 1: 0.1741708542713568}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.8258291457286432, 1: 0.1741708542713568}; total time=  12.3s\n",
      "[CV] END class_weight={0: 0.8308040201005026, 1: 0.16919597989949742}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.8308040201005026, 1: 0.16919597989949742}; total time=  10.3s\n",
      "[CV] END class_weight={0: 0.8308040201005026, 1: 0.16919597989949742}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.8308040201005026, 1: 0.16919597989949742}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.8308040201005026, 1: 0.16919597989949742}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.8357788944723619, 1: 0.16422110552763813}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.8357788944723619, 1: 0.16422110552763813}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.8357788944723619, 1: 0.16422110552763813}; total time=   9.2s\n",
      "[CV] END class_weight={0: 0.8407537688442211, 1: 0.15924623115577885}; total time=   8.8s\n",
      "[CV] END class_weight={0: 0.8357788944723619, 1: 0.16422110552763813}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.8407537688442211, 1: 0.15924623115577885}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.8357788944723619, 1: 0.16422110552763813}; total time=  12.0s\n",
      "[CV] END class_weight={0: 0.8407537688442211, 1: 0.15924623115577885}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.8407537688442211, 1: 0.15924623115577885}; total time=  11.6s\n",
      "[CV] END class_weight={0: 0.8407537688442211, 1: 0.15924623115577885}; total time=   8.8s\n",
      "[CV] END class_weight={0: 0.8457286432160804, 1: 0.15427135678391957}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.8457286432160804, 1: 0.15427135678391957}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.8457286432160804, 1: 0.15427135678391957}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.8457286432160804, 1: 0.15427135678391957}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.8457286432160804, 1: 0.15427135678391957}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.8507035175879397, 1: 0.14929648241206028}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.8507035175879397, 1: 0.14929648241206028}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.8507035175879397, 1: 0.14929648241206028}; total time=  11.9s\n",
      "[CV] END class_weight={0: 0.8507035175879397, 1: 0.14929648241206028}; total time=  10.6s\n",
      "[CV] END class_weight={0: 0.8507035175879397, 1: 0.14929648241206028}; total time=  11.4s\n",
      "[CV] END class_weight={0: 0.855678391959799, 1: 0.144321608040201}; total time=  11.3s\n",
      "[CV] END class_weight={0: 0.855678391959799, 1: 0.144321608040201}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.855678391959799, 1: 0.144321608040201}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.855678391959799, 1: 0.144321608040201}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.855678391959799, 1: 0.144321608040201}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.8606532663316583, 1: 0.13934673366834172}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.8606532663316583, 1: 0.13934673366834172}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.8656281407035176, 1: 0.13437185929648243}; total time=   8.3s\n",
      "[CV] END class_weight={0: 0.8606532663316583, 1: 0.13934673366834172}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.8606532663316583, 1: 0.13934673366834172}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.8606532663316583, 1: 0.13934673366834172}; total time=  11.1s\n",
      "[CV] END class_weight={0: 0.8656281407035176, 1: 0.13437185929648243}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.8656281407035176, 1: 0.13437185929648243}; total time=  10.7s\n",
      "[CV] END class_weight={0: 0.8656281407035176, 1: 0.13437185929648243}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.8656281407035176, 1: 0.13437185929648243}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.870603015075377, 1: 0.12939698492462304}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.870603015075377, 1: 0.12939698492462304}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.870603015075377, 1: 0.12939698492462304}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.870603015075377, 1: 0.12939698492462304}; total time=  10.5s\n",
      "[CV] END class_weight={0: 0.870603015075377, 1: 0.12939698492462304}; total time=   8.3s\n",
      "[CV] END class_weight={0: 0.8755778894472362, 1: 0.12442211055276375}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.8755778894472362, 1: 0.12442211055276375}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.8805527638190955, 1: 0.11944723618090447}; total time=   8.8s\n",
      "[CV] END class_weight={0: 0.8755778894472362, 1: 0.12442211055276375}; total time=  10.2s\n",
      "[CV] END class_weight={0: 0.8755778894472362, 1: 0.12442211055276375}; total time=  11.2s\n",
      "[CV] END class_weight={0: 0.8805527638190955, 1: 0.11944723618090447}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.8805527638190955, 1: 0.11944723618090447}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.8755778894472362, 1: 0.12442211055276375}; total time=  11.5s\n",
      "[CV] END class_weight={0: 0.8805527638190955, 1: 0.11944723618090447}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.8805527638190955, 1: 0.11944723618090447}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.8855276381909548, 1: 0.11447236180904519}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.8855276381909548, 1: 0.11447236180904519}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.8855276381909548, 1: 0.11447236180904519}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.8855276381909548, 1: 0.11447236180904519}; total time=  10.0s\n",
      "[CV] END class_weight={0: 0.8855276381909548, 1: 0.11447236180904519}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.8905025125628141, 1: 0.1094974874371859}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.8905025125628141, 1: 0.1094974874371859}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.8905025125628141, 1: 0.1094974874371859}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.8905025125628141, 1: 0.1094974874371859}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.8905025125628141, 1: 0.1094974874371859}; total time=   9.6s\n",
      "[CV] END class_weight={0: 0.8954773869346734, 1: 0.10452261306532662}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.8954773869346734, 1: 0.10452261306532662}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.8954773869346734, 1: 0.10452261306532662}; total time=  10.4s\n",
      "[CV] END class_weight={0: 0.8954773869346734, 1: 0.10452261306532662}; total time=  10.8s\n",
      "[CV] END class_weight={0: 0.8954773869346734, 1: 0.10452261306532662}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.9004522613065327, 1: 0.09954773869346734}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.9004522613065327, 1: 0.09954773869346734}; total time=   8.5s\n",
      "[CV] END class_weight={0: 0.9004522613065327, 1: 0.09954773869346734}; total time=   8.5s\n",
      "[CV] END class_weight={0: 0.9004522613065327, 1: 0.09954773869346734}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.9004522613065327, 1: 0.09954773869346734}; total time=   8.3s\n",
      "[CV] END class_weight={0: 0.905427135678392, 1: 0.09457286432160805}; total time=   8.7s\n",
      "[CV] END class_weight={0: 0.905427135678392, 1: 0.09457286432160805}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.905427135678392, 1: 0.09457286432160805}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.905427135678392, 1: 0.09457286432160805}; total time=   9.9s\n",
      "[CV] END class_weight={0: 0.905427135678392, 1: 0.09457286432160805}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.9104020100502512, 1: 0.08959798994974877}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.9104020100502512, 1: 0.08959798994974877}; total time=  11.0s\n",
      "[CV] END class_weight={0: 0.9104020100502512, 1: 0.08959798994974877}; total time=   8.8s\n",
      "[CV] END class_weight={0: 0.9104020100502512, 1: 0.08959798994974877}; total time=   9.2s\n",
      "[CV] END class_weight={0: 0.9104020100502512, 1: 0.08959798994974877}; total time=  10.9s\n",
      "[CV] END class_weight={0: 0.9153768844221106, 1: 0.08462311557788937}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.9153768844221106, 1: 0.08462311557788937}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.9153768844221106, 1: 0.08462311557788937}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.9153768844221106, 1: 0.08462311557788937}; total time=   9.7s\n",
      "[CV] END class_weight={0: 0.9153768844221106, 1: 0.08462311557788937}; total time=   9.5s\n",
      "[CV] END class_weight={0: 0.9203517587939699, 1: 0.07964824120603009}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.9203517587939699, 1: 0.07964824120603009}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.9203517587939699, 1: 0.07964824120603009}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.9203517587939699, 1: 0.07964824120603009}; total time=   8.3s\n",
      "[CV] END class_weight={0: 0.9203517587939699, 1: 0.07964824120603009}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.9253266331658292, 1: 0.0746733668341708}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.9253266331658292, 1: 0.0746733668341708}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.9253266331658292, 1: 0.0746733668341708}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.9303015075376885, 1: 0.06969849246231152}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.9253266331658292, 1: 0.0746733668341708}; total time=   8.9s\n",
      "[CV] END class_weight={0: 0.9253266331658292, 1: 0.0746733668341708}; total time=   9.8s\n",
      "[CV] END class_weight={0: 0.9303015075376885, 1: 0.06969849246231152}; total time=   9.3s\n",
      "[CV] END class_weight={0: 0.9303015075376885, 1: 0.06969849246231152}; total time=   7.7s\n",
      "[CV] END class_weight={0: 0.9303015075376885, 1: 0.06969849246231152}; total time=   9.4s\n",
      "[CV] END class_weight={0: 0.9303015075376885, 1: 0.06969849246231152}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.9352763819095478, 1: 0.06472361809045224}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.9352763819095478, 1: 0.06472361809045224}; total time=   8.8s\n",
      "[CV] END class_weight={0: 0.9352763819095478, 1: 0.06472361809045224}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.9352763819095478, 1: 0.06472361809045224}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.9352763819095478, 1: 0.06472361809045224}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.940251256281407, 1: 0.059748743718592956}; total time=   8.5s\n",
      "[CV] END class_weight={0: 0.940251256281407, 1: 0.059748743718592956}; total time=   8.0s\n",
      "[CV] END class_weight={0: 0.940251256281407, 1: 0.059748743718592956}; total time=   8.5s\n",
      "[CV] END class_weight={0: 0.9452261306532663, 1: 0.05477386934673367}; total time=   7.8s\n",
      "[CV] END class_weight={0: 0.940251256281407, 1: 0.059748743718592956}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.940251256281407, 1: 0.059748743718592956}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.9452261306532663, 1: 0.05477386934673367}; total time=   9.0s\n",
      "[CV] END class_weight={0: 0.9452261306532663, 1: 0.05477386934673367}; total time=   8.8s\n",
      "[CV] END class_weight={0: 0.9452261306532663, 1: 0.05477386934673367}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.9452261306532663, 1: 0.05477386934673367}; total time=   8.0s\n",
      "[CV] END class_weight={0: 0.9502010050251256, 1: 0.04979899497487439}; total time=   7.5s\n",
      "[CV] END class_weight={0: 0.9502010050251256, 1: 0.04979899497487439}; total time=   7.9s\n",
      "[CV] END class_weight={0: 0.9502010050251256, 1: 0.04979899497487439}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.9502010050251256, 1: 0.04979899497487439}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.9502010050251256, 1: 0.04979899497487439}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.9551758793969849, 1: 0.044824120603015105}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.9551758793969849, 1: 0.044824120603015105}; total time=   8.4s\n",
      "[CV] END class_weight={0: 0.9551758793969849, 1: 0.044824120603015105}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.9551758793969849, 1: 0.044824120603015105}; total time=   8.0s\n",
      "[CV] END class_weight={0: 0.9551758793969849, 1: 0.044824120603015105}; total time=   7.9s\n",
      "[CV] END class_weight={0: 0.9601507537688443, 1: 0.03984924623115571}; total time=   8.7s\n",
      "[CV] END class_weight={0: 0.9601507537688443, 1: 0.03984924623115571}; total time=   7.8s\n",
      "[CV] END class_weight={0: 0.9601507537688443, 1: 0.03984924623115571}; total time=   8.2s\n",
      "[CV] END class_weight={0: 0.9601507537688443, 1: 0.03984924623115571}; total time=   7.3s\n",
      "[CV] END class_weight={0: 0.9601507537688443, 1: 0.03984924623115571}; total time=   7.4s\n",
      "[CV] END class_weight={0: 0.9651256281407036, 1: 0.03487437185929643}; total time=   7.5s\n",
      "[CV] END class_weight={0: 0.9651256281407036, 1: 0.03487437185929643}; total time=   9.1s\n",
      "[CV] END class_weight={0: 0.9651256281407036, 1: 0.03487437185929643}; total time=   8.6s\n",
      "[CV] END class_weight={0: 0.9651256281407036, 1: 0.03487437185929643}; total time=   7.3s\n",
      "[CV] END class_weight={0: 0.9651256281407036, 1: 0.03487437185929643}; total time=   7.4s\n",
      "[CV] END class_weight={0: 0.9701005025125629, 1: 0.029899497487437143}; total time=   7.2s\n",
      "[CV] END class_weight={0: 0.9701005025125629, 1: 0.029899497487437143}; total time=   6.9s\n",
      "[CV] END class_weight={0: 0.9701005025125629, 1: 0.029899497487437143}; total time=   7.4s\n",
      "[CV] END class_weight={0: 0.9701005025125629, 1: 0.029899497487437143}; total time=   7.1s\n",
      "[CV] END class_weight={0: 0.9701005025125629, 1: 0.029899497487437143}; total time=   7.0s\n",
      "[CV] END class_weight={0: 0.9750753768844221, 1: 0.02492462311557786}; total time=   7.0s\n",
      "[CV] END class_weight={0: 0.9750753768844221, 1: 0.02492462311557786}; total time=   7.3s\n",
      "[CV] END class_weight={0: 0.9750753768844221, 1: 0.02492462311557786}; total time=   7.5s\n",
      "[CV] END class_weight={0: 0.9750753768844221, 1: 0.02492462311557786}; total time=   6.4s\n",
      "[CV] END class_weight={0: 0.9750753768844221, 1: 0.02492462311557786}; total time=   7.0s\n",
      "[CV] END class_weight={0: 0.9800502512562814, 1: 0.019949748743718576}; total time=   6.8s\n",
      "[CV] END class_weight={0: 0.9800502512562814, 1: 0.019949748743718576}; total time=   6.9s\n",
      "[CV] END class_weight={0: 0.9800502512562814, 1: 0.019949748743718576}; total time=   7.0s\n",
      "[CV] END class_weight={0: 0.9800502512562814, 1: 0.019949748743718576}; total time=   6.3s\n",
      "[CV] END class_weight={0: 0.9800502512562814, 1: 0.019949748743718576}; total time=   6.6s\n",
      "[CV] END class_weight={0: 0.9850251256281407, 1: 0.014974874371859292}; total time=   6.7s\n",
      "[CV] END class_weight={0: 0.9850251256281407, 1: 0.014974874371859292}; total time=   7.4s\n",
      "[CV] END class_weight={0: 0.9850251256281407, 1: 0.014974874371859292}; total time=   6.5s\n",
      "[CV] END class_weight={0: 0.9850251256281407, 1: 0.014974874371859292}; total time=   6.7s\n",
      "[CV] END class_weight={0: 0.9850251256281407, 1: 0.014974874371859292}; total time=   6.5s\n",
      "[CV] END ....class_weight={0: 0.99, 1: 0.010000000000000009}; total time=   4.7s\n",
      "[CV] END ....class_weight={0: 0.99, 1: 0.010000000000000009}; total time=   5.4s\n",
      "[CV] END ....class_weight={0: 0.99, 1: 0.010000000000000009}; total time=   3.8s\n",
      "[CV] END ....class_weight={0: 0.99, 1: 0.010000000000000009}; total time=   5.9s\n",
      "[CV] END ....class_weight={0: 0.99, 1: 0.010000000000000009}; total time=   4.5s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "lr = LogisticRegression(random_state=0,solver='newton-cg', fit_intercept=True, penalty='l2' )\n",
    "\n",
    "#Setting the range for class weights\n",
    "weights = np.linspace(0.0,0.99,200)\n",
    "\n",
    "#Creating a dictionary grid for grid search\n",
    "param_grid = {'class_weight': [{0:x, 1:1.0-x} for x in weights]}\n",
    "\n",
    "#Fitting grid search to the train data with 5 folds\n",
    "gridsearch = GridSearchCV(estimator= lr, \n",
    "                          param_grid= param_grid,\n",
    "                          cv=StratifiedKFold(), \n",
    "                          n_jobs=-1, \n",
    "                          scoring='recall', \n",
    "                          verbose=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caanpaip/miniconda3/envs/env_ml/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression( random_state=0, solver='saga',l1_ratio = 0.1, fit_intercept=True, penalty='elasticnet', class_weight = \"balanced\" )\n",
    "\n",
    "model = clf.fit(X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9512/2283094811.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2_model['probabilty'] = model.predict_proba(X)[:,1]\n"
     ]
    }
   ],
   "source": [
    "df_2_model['probabilty'] = model.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='weight', ylabel='score'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ploting the score for different values of weight\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(12,8))\n",
    "weigh_data = pd.DataFrame({ 'score': gridsearch.cv_results_['mean_test_score'], 'weight': (1-weights)})\n",
    "sns.lineplot(weigh_data,  x='weight', y='score')\n",
    "# plt.xlabel('Weight for class 1')\n",
    "# plt.ylabel('F1 score')\n",
    "# plt.xticks([round(i/10,1) for i in range(0,11,1)])\n",
    "# plt.title('Scoring for different class weights', fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>IV_var</th>\n",
       "      <th>KS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fecha</td>\n",
       "      <td>12.113640</td>\n",
       "      <td>99.544561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>produto</td>\n",
       "      <td>6.369097</td>\n",
       "      <td>88.306667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hora</td>\n",
       "      <td>4.346361</td>\n",
       "      <td>84.314386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>categoria_produto</td>\n",
       "      <td>1.641776</td>\n",
       "      <td>39.766316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o_obj</td>\n",
       "      <td>1.094238</td>\n",
       "      <td>44.994386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>score</td>\n",
       "      <td>1.021894</td>\n",
       "      <td>43.152982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f_float</td>\n",
       "      <td>0.447805</td>\n",
       "      <td>27.785965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l_float</td>\n",
       "      <td>0.439939</td>\n",
       "      <td>25.305965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_boolean</td>\n",
       "      <td>0.361450</td>\n",
       "      <td>22.844211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m_float</td>\n",
       "      <td>0.337380</td>\n",
       "      <td>22.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p_boolean</td>\n",
       "      <td>0.245520</td>\n",
       "      <td>24.357193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d_float</td>\n",
       "      <td>0.170619</td>\n",
       "      <td>16.508070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b_float</td>\n",
       "      <td>0.093757</td>\n",
       "      <td>11.223158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>monto</td>\n",
       "      <td>0.093325</td>\n",
       "      <td>9.863860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a_int</td>\n",
       "      <td>0.064728</td>\n",
       "      <td>9.823860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h_float</td>\n",
       "      <td>0.061916</td>\n",
       "      <td>8.569825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pais</td>\n",
       "      <td>0.042895</td>\n",
       "      <td>8.446316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c_float</td>\n",
       "      <td>0.036743</td>\n",
       "      <td>4.081404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e_float</td>\n",
       "      <td>0.029034</td>\n",
       "      <td>8.440702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>6.282105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k_float</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.563509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fraude</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            variable     IV_var         KS\n",
       "0              fecha  12.113640  99.544561\n",
       "0            produto   6.369097  88.306667\n",
       "0               hora   4.346361  84.314386\n",
       "0  categoria_produto   1.641776  39.766316\n",
       "0              o_obj   1.094238  44.994386\n",
       "0              score   1.021894  43.152982\n",
       "0            f_float   0.447805  27.785965\n",
       "0            l_float   0.439939  25.305965\n",
       "0          n_boolean   0.361450  22.844211\n",
       "0            m_float   0.337380  22.929825\n",
       "0          p_boolean   0.245520  24.357193\n",
       "0            d_float   0.170619  16.508070\n",
       "0            b_float   0.093757  11.223158\n",
       "0              monto   0.093325   9.863860\n",
       "0              a_int   0.064728   9.823860\n",
       "0            h_float   0.061916   8.569825\n",
       "0               pais   0.042895   8.446316\n",
       "0            c_float   0.036743   4.081404\n",
       "0            e_float   0.029034   8.440702\n",
       "0               data   0.029014   6.282105\n",
       "0            k_float   0.000509   0.563509\n",
       "0             fraude   0.000000   0.000000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ivs_ls = []\n",
    "\n",
    "for variable in dff.columns.tolist():\n",
    "\n",
    "    label = \"fraude\"\n",
    "    dtype_ = 'categorical' if dff[variable].dtype=='O' or dff[variable].dtype=='category' else 'numerical'\n",
    "\n",
    "    df_iv = utils_ml.WOE_IV(df = dff , variable = variable, dtype_ = dtype_ , label = label, monotonic= True)[[ 'variable' , 'IV_var', 'KS']].drop_duplicates()\n",
    "\n",
    "    df_ivs_ls.append(df_iv)\n",
    "\n",
    "pd.concat(df_ivs_ls).sort_values(\"IV_var\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cols</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>categoria_produto_bins_10</td>\n",
       "      <td>3.772181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>m_float_bins_1</td>\n",
       "      <td>2.835021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>categoria_produto_bins_11</td>\n",
       "      <td>2.560564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>o_obj_bins_1</td>\n",
       "      <td>1.784606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>categoria_produto_bins_5</td>\n",
       "      <td>1.609129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>l_float_bins_1</td>\n",
       "      <td>1.338140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>m_float_bins_0</td>\n",
       "      <td>1.281945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>d_float_bins_3</td>\n",
       "      <td>1.252341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>l_float_bins_7</td>\n",
       "      <td>1.166217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>f_float_bins_1</td>\n",
       "      <td>1.163016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>h_float_bins_3</td>\n",
       "      <td>1.108947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>l_float_bins_6</td>\n",
       "      <td>1.086290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>categoria_produto_bins_9</td>\n",
       "      <td>1.025790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>h_float_bins_0</td>\n",
       "      <td>0.997046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>b_float_bins_2</td>\n",
       "      <td>0.935989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pais_bins_1</td>\n",
       "      <td>0.862649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>monto_bins_5</td>\n",
       "      <td>0.846944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>b_float_bins_1</td>\n",
       "      <td>0.740437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>f_float_bins_6</td>\n",
       "      <td>0.708460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>o_obj_bins_0</td>\n",
       "      <td>0.669458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>f_float_bins_8</td>\n",
       "      <td>0.662283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>b_float_bins_5</td>\n",
       "      <td>0.603343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>categoria_produto_bins_8</td>\n",
       "      <td>0.551608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>l_float_bins_0</td>\n",
       "      <td>0.506450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>categoria_produto_bins_7</td>\n",
       "      <td>0.495149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>f_float_bins_5</td>\n",
       "      <td>0.466140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>k_float_bins_0</td>\n",
       "      <td>0.461322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>f_float_bins_4</td>\n",
       "      <td>0.430280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>h_float_bins_1</td>\n",
       "      <td>0.405643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>d_float_bins_-1</td>\n",
       "      <td>0.404486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>m_float_bins_-1</td>\n",
       "      <td>0.404486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>d_float_bins_4</td>\n",
       "      <td>0.377631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>monto_bins_3</td>\n",
       "      <td>0.301673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>monto_bins_2</td>\n",
       "      <td>0.301662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>m_float_bins_7</td>\n",
       "      <td>0.287533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>c_float_bins_0</td>\n",
       "      <td>0.280378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n_boolean_bins_1</td>\n",
       "      <td>0.276500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>l_float_bins_3</td>\n",
       "      <td>0.266520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>d_float_bins_2</td>\n",
       "      <td>0.248193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>b_float_bins_0</td>\n",
       "      <td>0.189777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>l_float_bins_9</td>\n",
       "      <td>0.152652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>a_int_bins_0</td>\n",
       "      <td>0.145627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>l_float_bins_2</td>\n",
       "      <td>0.139610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>e_float_bins_1</td>\n",
       "      <td>0.099543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>f_float_bins_10</td>\n",
       "      <td>0.087028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>k_float_bins_1</td>\n",
       "      <td>0.082160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p_boolean_bins_0</td>\n",
       "      <td>0.049689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>l_float_bins_8</td>\n",
       "      <td>-0.010698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>e_float_bins_0</td>\n",
       "      <td>-0.028223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>d_float_bins_1</td>\n",
       "      <td>-0.078486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>categoria_produto_bins_6</td>\n",
       "      <td>-0.100774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>l_float_bins_4</td>\n",
       "      <td>-0.150735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>m_float_bins_5</td>\n",
       "      <td>-0.195940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>categoria_produto_bins_4</td>\n",
       "      <td>-0.214525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>m_float_bins_3</td>\n",
       "      <td>-0.215161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pais_bins_-1</td>\n",
       "      <td>-0.278776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>h_float_bins_2</td>\n",
       "      <td>-0.301321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>h_float_bins_5</td>\n",
       "      <td>-0.315301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>b_float_bins_6</td>\n",
       "      <td>-0.329679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>h_float_bins_4</td>\n",
       "      <td>-0.369450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>b_float_bins_-1</td>\n",
       "      <td>-0.377568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>c_float_bins_-1</td>\n",
       "      <td>-0.377568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>c_float_bins_1</td>\n",
       "      <td>-0.412975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>b_float_bins_3</td>\n",
       "      <td>-0.415588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>f_float_bins_3</td>\n",
       "      <td>-0.421146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>f_float_bins_7</td>\n",
       "      <td>-0.433452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>monto_bins_1</td>\n",
       "      <td>-0.466371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>categoria_produto_bins_3</td>\n",
       "      <td>-0.497604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>f_float_bins_0</td>\n",
       "      <td>-0.553963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p_boolean_bins_1</td>\n",
       "      <td>-0.560665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>e_float_bins_2</td>\n",
       "      <td>-0.586335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>a_int_bins_1</td>\n",
       "      <td>-0.654452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>monto_bins_4</td>\n",
       "      <td>-0.713416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>m_float_bins_8</td>\n",
       "      <td>-0.716321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>m_float_bins_9</td>\n",
       "      <td>-0.724157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>f_float_bins_2</td>\n",
       "      <td>-0.729256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_boolean_bins_0</td>\n",
       "      <td>-0.784754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>f_float_bins_-1</td>\n",
       "      <td>-0.798089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>l_float_bins_-1</td>\n",
       "      <td>-0.798089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>monto_bins_0</td>\n",
       "      <td>-0.798427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>m_float_bins_4</td>\n",
       "      <td>-0.826391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>k_float_bins_2</td>\n",
       "      <td>-1.056105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>f_float_bins_9</td>\n",
       "      <td>-1.056861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>l_float_bins_10</td>\n",
       "      <td>-1.094194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pais_bins_0</td>\n",
       "      <td>-1.096787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>categoria_produto_bins_1</td>\n",
       "      <td>-1.124370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>m_float_bins_6</td>\n",
       "      <td>-1.210351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>categoria_produto_bins_2</td>\n",
       "      <td>-1.217852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>l_float_bins_5</td>\n",
       "      <td>-1.285665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>m_float_bins_2</td>\n",
       "      <td>-1.349491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>d_float_bins_0</td>\n",
       "      <td>-1.361010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>d_float_bins_5</td>\n",
       "      <td>-1.389650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>l_float_bins_11</td>\n",
       "      <td>-1.797204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>b_float_bins_4</td>\n",
       "      <td>-1.855567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>h_float_bins_6</td>\n",
       "      <td>-2.034422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>o_obj_bins_-1</td>\n",
       "      <td>-3.038215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>categoria_produto_bins_0</td>\n",
       "      <td>-7.614170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Cols      coef\n",
       "14  categoria_produto_bins_10  3.772181\n",
       "82             m_float_bins_1  2.835021\n",
       "15  categoria_produto_bins_11  2.560564\n",
       "18               o_obj_bins_1  1.784606\n",
       "9    categoria_produto_bins_5  1.609129\n",
       "69             l_float_bins_1  1.338140\n",
       "81             m_float_bins_0  1.281945\n",
       "39             d_float_bins_3  1.252341\n",
       "75             l_float_bins_7  1.166217\n",
       "47             f_float_bins_1  1.163016\n",
       "60             h_float_bins_3  1.108947\n",
       "74             l_float_bins_6  1.086290\n",
       "13   categoria_produto_bins_9  1.025790\n",
       "57             h_float_bins_0  0.997046\n",
       "27             b_float_bins_2  0.935989\n",
       "21                pais_bins_1  0.862649\n",
       "96               monto_bins_5  0.846944\n",
       "26             b_float_bins_1  0.740437\n",
       "52             f_float_bins_6  0.708460\n",
       "17               o_obj_bins_0  0.669458\n",
       "54             f_float_bins_8  0.662283\n",
       "30             b_float_bins_5  0.603343\n",
       "12   categoria_produto_bins_8  0.551608\n",
       "68             l_float_bins_0  0.506450\n",
       "11   categoria_produto_bins_7  0.495149\n",
       "51             f_float_bins_5  0.466140\n",
       "64             k_float_bins_0  0.461322\n",
       "50             f_float_bins_4  0.430280\n",
       "58             h_float_bins_1  0.405643\n",
       "35            d_float_bins_-1  0.404486\n",
       "80            m_float_bins_-1  0.404486\n",
       "40             d_float_bins_4  0.377631\n",
       "94               monto_bins_3  0.301673\n",
       "93               monto_bins_2  0.301662\n",
       "88             m_float_bins_7  0.287533\n",
       "33             c_float_bins_0  0.280378\n",
       "1            n_boolean_bins_1  0.276500\n",
       "71             l_float_bins_3  0.266520\n",
       "38             d_float_bins_2  0.248193\n",
       "25             b_float_bins_0  0.189777\n",
       "77             l_float_bins_9  0.152652\n",
       "22               a_int_bins_0  0.145627\n",
       "70             l_float_bins_2  0.139610\n",
       "43             e_float_bins_1  0.099543\n",
       "56            f_float_bins_10  0.087028\n",
       "65             k_float_bins_1  0.082160\n",
       "2            p_boolean_bins_0  0.049689\n",
       "76             l_float_bins_8 -0.010698\n",
       "42             e_float_bins_0 -0.028223\n",
       "37             d_float_bins_1 -0.078486\n",
       "10   categoria_produto_bins_6 -0.100774\n",
       "72             l_float_bins_4 -0.150735\n",
       "86             m_float_bins_5 -0.195940\n",
       "8    categoria_produto_bins_4 -0.214525\n",
       "84             m_float_bins_3 -0.215161\n",
       "19               pais_bins_-1 -0.278776\n",
       "59             h_float_bins_2 -0.301321\n",
       "62             h_float_bins_5 -0.315301\n",
       "31             b_float_bins_6 -0.329679\n",
       "61             h_float_bins_4 -0.369450\n",
       "24            b_float_bins_-1 -0.377568\n",
       "32            c_float_bins_-1 -0.377568\n",
       "34             c_float_bins_1 -0.412975\n",
       "28             b_float_bins_3 -0.415588\n",
       "49             f_float_bins_3 -0.421146\n",
       "53             f_float_bins_7 -0.433452\n",
       "92               monto_bins_1 -0.466371\n",
       "7    categoria_produto_bins_3 -0.497604\n",
       "46             f_float_bins_0 -0.553963\n",
       "3            p_boolean_bins_1 -0.560665\n",
       "44             e_float_bins_2 -0.586335\n",
       "23               a_int_bins_1 -0.654452\n",
       "95               monto_bins_4 -0.713416\n",
       "89             m_float_bins_8 -0.716321\n",
       "90             m_float_bins_9 -0.724157\n",
       "48             f_float_bins_2 -0.729256\n",
       "0            n_boolean_bins_0 -0.784754\n",
       "45            f_float_bins_-1 -0.798089\n",
       "67            l_float_bins_-1 -0.798089\n",
       "91               monto_bins_0 -0.798427\n",
       "85             m_float_bins_4 -0.826391\n",
       "66             k_float_bins_2 -1.056105\n",
       "55             f_float_bins_9 -1.056861\n",
       "78            l_float_bins_10 -1.094194\n",
       "20                pais_bins_0 -1.096787\n",
       "5    categoria_produto_bins_1 -1.124370\n",
       "87             m_float_bins_6 -1.210351\n",
       "6    categoria_produto_bins_2 -1.217852\n",
       "73             l_float_bins_5 -1.285665\n",
       "83             m_float_bins_2 -1.349491\n",
       "36             d_float_bins_0 -1.361010\n",
       "41             d_float_bins_5 -1.389650\n",
       "79            l_float_bins_11 -1.797204\n",
       "29             b_float_bins_4 -1.855567\n",
       "63             h_float_bins_6 -2.034422\n",
       "16              o_obj_bins_-1 -3.038215\n",
       "4    categoria_produto_bins_0 -7.614170"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame( {\"Cols\": model.feature_names_in_,  \"coef\": model.coef_[0] })\n",
    "coef_df.sort_values(\"coef\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>faixa_prob</th>\n",
       "      <th>total_um</th>\n",
       "      <th>total_zero</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>perc_um</th>\n",
       "      <th>perc_zero</th>\n",
       "      <th>csum_um</th>\n",
       "      <th>csum_zero</th>\n",
       "      <th>ks</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>specificity</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantil</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0, 8]</td>\n",
       "      <td>417</td>\n",
       "      <td>14583</td>\n",
       "      <td>7500</td>\n",
       "      <td>142500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.560000</td>\n",
       "      <td>10.233684</td>\n",
       "      <td>5.560000</td>\n",
       "      <td>10.233684</td>\n",
       "      <td>42.42807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15000</td>\n",
       "      <td>[8, 18]</td>\n",
       "      <td>694</td>\n",
       "      <td>14306</td>\n",
       "      <td>7083</td>\n",
       "      <td>127917</td>\n",
       "      <td>14583</td>\n",
       "      <td>417</td>\n",
       "      <td>9.253333</td>\n",
       "      <td>10.039298</td>\n",
       "      <td>14.813333</td>\n",
       "      <td>20.272982</td>\n",
       "      <td>42.42807</td>\n",
       "      <td>0.944400</td>\n",
       "      <td>0.052467</td>\n",
       "      <td>0.102337</td>\n",
       "      <td>0.099411</td>\n",
       "      <td>0.214636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15000</td>\n",
       "      <td>[18, 28]</td>\n",
       "      <td>492</td>\n",
       "      <td>14508</td>\n",
       "      <td>6389</td>\n",
       "      <td>113611</td>\n",
       "      <td>28889</td>\n",
       "      <td>1111</td>\n",
       "      <td>6.560000</td>\n",
       "      <td>10.181053</td>\n",
       "      <td>21.373333</td>\n",
       "      <td>30.454035</td>\n",
       "      <td>42.42807</td>\n",
       "      <td>0.851867</td>\n",
       "      <td>0.053242</td>\n",
       "      <td>0.202730</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.212967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15000</td>\n",
       "      <td>[28, 38]</td>\n",
       "      <td>45</td>\n",
       "      <td>14955</td>\n",
       "      <td>5897</td>\n",
       "      <td>99103</td>\n",
       "      <td>43397</td>\n",
       "      <td>1603</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>10.494737</td>\n",
       "      <td>21.973333</td>\n",
       "      <td>40.948772</td>\n",
       "      <td>42.42807</td>\n",
       "      <td>0.786267</td>\n",
       "      <td>0.056162</td>\n",
       "      <td>0.304540</td>\n",
       "      <td>0.104836</td>\n",
       "      <td>0.218407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15000</td>\n",
       "      <td>[38, 48]</td>\n",
       "      <td>91</td>\n",
       "      <td>14909</td>\n",
       "      <td>5852</td>\n",
       "      <td>84148</td>\n",
       "      <td>58352</td>\n",
       "      <td>1648</td>\n",
       "      <td>1.213333</td>\n",
       "      <td>10.462456</td>\n",
       "      <td>23.186667</td>\n",
       "      <td>51.411228</td>\n",
       "      <td>42.42807</td>\n",
       "      <td>0.780267</td>\n",
       "      <td>0.065022</td>\n",
       "      <td>0.409488</td>\n",
       "      <td>0.120041</td>\n",
       "      <td>0.243833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15000</td>\n",
       "      <td>[48, 58]</td>\n",
       "      <td>195</td>\n",
       "      <td>14805</td>\n",
       "      <td>5761</td>\n",
       "      <td>69239</td>\n",
       "      <td>73261</td>\n",
       "      <td>1739</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>10.389474</td>\n",
       "      <td>25.786667</td>\n",
       "      <td>61.800702</td>\n",
       "      <td>42.42807</td>\n",
       "      <td>0.768133</td>\n",
       "      <td>0.076813</td>\n",
       "      <td>0.514112</td>\n",
       "      <td>0.139661</td>\n",
       "      <td>0.274333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15000</td>\n",
       "      <td>[58, 68]</td>\n",
       "      <td>293</td>\n",
       "      <td>14707</td>\n",
       "      <td>5566</td>\n",
       "      <td>54434</td>\n",
       "      <td>88066</td>\n",
       "      <td>1934</td>\n",
       "      <td>3.906667</td>\n",
       "      <td>10.320702</td>\n",
       "      <td>29.693333</td>\n",
       "      <td>72.121404</td>\n",
       "      <td>42.42807</td>\n",
       "      <td>0.742133</td>\n",
       "      <td>0.092767</td>\n",
       "      <td>0.618007</td>\n",
       "      <td>0.164919</td>\n",
       "      <td>0.309222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15000</td>\n",
       "      <td>[68, 78]</td>\n",
       "      <td>783</td>\n",
       "      <td>14217</td>\n",
       "      <td>5273</td>\n",
       "      <td>39727</td>\n",
       "      <td>102773</td>\n",
       "      <td>2227</td>\n",
       "      <td>10.440000</td>\n",
       "      <td>9.976842</td>\n",
       "      <td>40.133333</td>\n",
       "      <td>82.098246</td>\n",
       "      <td>42.42807</td>\n",
       "      <td>0.703067</td>\n",
       "      <td>0.117178</td>\n",
       "      <td>0.721214</td>\n",
       "      <td>0.200876</td>\n",
       "      <td>0.351533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15000</td>\n",
       "      <td>[78, 88]</td>\n",
       "      <td>1295</td>\n",
       "      <td>13705</td>\n",
       "      <td>4490</td>\n",
       "      <td>25510</td>\n",
       "      <td>116990</td>\n",
       "      <td>3010</td>\n",
       "      <td>17.266667</td>\n",
       "      <td>9.617544</td>\n",
       "      <td>57.400000</td>\n",
       "      <td>91.715789</td>\n",
       "      <td>42.42807</td>\n",
       "      <td>0.598667</td>\n",
       "      <td>0.149667</td>\n",
       "      <td>0.820982</td>\n",
       "      <td>0.239467</td>\n",
       "      <td>0.374167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15000</td>\n",
       "      <td>[88, 100]</td>\n",
       "      <td>3195</td>\n",
       "      <td>11805</td>\n",
       "      <td>3195</td>\n",
       "      <td>11805</td>\n",
       "      <td>130695</td>\n",
       "      <td>4305</td>\n",
       "      <td>42.600000</td>\n",
       "      <td>8.284211</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>42.42807</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>0.917158</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.355000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         total faixa_prob  total_um  total_zero    TP      FP      TN    FN    perc_um  perc_zero     csum_um   csum_zero        ks    recall  precision  specificity        F1        F2\n",
       "quantil                                                                                                                                                                                  \n",
       "0        15000     [0, 8]       417       14583  7500  142500       0     0   5.560000  10.233684    5.560000   10.233684  42.42807  1.000000   0.050000     0.000000  0.095238  0.208333\n",
       "1        15000    [8, 18]       694       14306  7083  127917   14583   417   9.253333  10.039298   14.813333   20.272982  42.42807  0.944400   0.052467     0.102337  0.099411  0.214636\n",
       "2        15000   [18, 28]       492       14508  6389  113611   28889  1111   6.560000  10.181053   21.373333   30.454035  42.42807  0.851867   0.053242     0.202730  0.100220  0.212967\n",
       "3        15000   [28, 38]        45       14955  5897   99103   43397  1603   0.600000  10.494737   21.973333   40.948772  42.42807  0.786267   0.056162     0.304540  0.104836  0.218407\n",
       "4        15000   [38, 48]        91       14909  5852   84148   58352  1648   1.213333  10.462456   23.186667   51.411228  42.42807  0.780267   0.065022     0.409488  0.120041  0.243833\n",
       "5        15000   [48, 58]       195       14805  5761   69239   73261  1739   2.600000  10.389474   25.786667   61.800702  42.42807  0.768133   0.076813     0.514112  0.139661  0.274333\n",
       "6        15000   [58, 68]       293       14707  5566   54434   88066  1934   3.906667  10.320702   29.693333   72.121404  42.42807  0.742133   0.092767     0.618007  0.164919  0.309222\n",
       "7        15000   [68, 78]       783       14217  5273   39727  102773  2227  10.440000   9.976842   40.133333   82.098246  42.42807  0.703067   0.117178     0.721214  0.200876  0.351533\n",
       "8        15000   [78, 88]      1295       13705  4490   25510  116990  3010  17.266667   9.617544   57.400000   91.715789  42.42807  0.598667   0.149667     0.820982  0.239467  0.374167\n",
       "9        15000  [88, 100]      3195       11805  3195   11805  130695  4305  42.600000   8.284211  100.000000  100.000000  42.42807  0.426000   0.213000     0.917158  0.284000  0.355000"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability = \"score\"\n",
    "label=\"fraude\"\n",
    "quantil=10\n",
    "\n",
    "utils_ml.metric_evaluation(df, probability, label, quantil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>faixa_prob</th>\n",
       "      <th>total_um</th>\n",
       "      <th>total_zero</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>perc_um</th>\n",
       "      <th>perc_zero</th>\n",
       "      <th>csum_um</th>\n",
       "      <th>csum_zero</th>\n",
       "      <th>ks</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>specificity</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantil</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>[6.252292182237895e-11, 1.5407916538275171e-06]</td>\n",
       "      <td>2</td>\n",
       "      <td>14998</td>\n",
       "      <td>7500</td>\n",
       "      <td>142500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>10.524912</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>10.524912</td>\n",
       "      <td>52.392982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15000</td>\n",
       "      <td>[1.5411497531130377e-06, 2.8416336743983467e-05]</td>\n",
       "      <td>12</td>\n",
       "      <td>14988</td>\n",
       "      <td>7498</td>\n",
       "      <td>127502</td>\n",
       "      <td>14998</td>\n",
       "      <td>2</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>10.517895</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>21.042807</td>\n",
       "      <td>52.392982</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>0.055541</td>\n",
       "      <td>0.105249</td>\n",
       "      <td>0.105235</td>\n",
       "      <td>0.227212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15000</td>\n",
       "      <td>[2.8419583485992328e-05, 0.0003183443394388212]</td>\n",
       "      <td>96</td>\n",
       "      <td>14904</td>\n",
       "      <td>7486</td>\n",
       "      <td>112514</td>\n",
       "      <td>29986</td>\n",
       "      <td>14</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>10.458947</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>31.501754</td>\n",
       "      <td>52.392982</td>\n",
       "      <td>0.998133</td>\n",
       "      <td>0.062383</td>\n",
       "      <td>0.210428</td>\n",
       "      <td>0.117427</td>\n",
       "      <td>0.249533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.0003183550525651636, 0.0016153505865386328]</td>\n",
       "      <td>173</td>\n",
       "      <td>14827</td>\n",
       "      <td>7390</td>\n",
       "      <td>97610</td>\n",
       "      <td>44890</td>\n",
       "      <td>110</td>\n",
       "      <td>2.306667</td>\n",
       "      <td>10.404912</td>\n",
       "      <td>3.773333</td>\n",
       "      <td>41.906667</td>\n",
       "      <td>52.392982</td>\n",
       "      <td>0.985333</td>\n",
       "      <td>0.070381</td>\n",
       "      <td>0.315018</td>\n",
       "      <td>0.131378</td>\n",
       "      <td>0.273704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.0016154123547990067, 0.00586593409276533]</td>\n",
       "      <td>287</td>\n",
       "      <td>14713</td>\n",
       "      <td>7217</td>\n",
       "      <td>82783</td>\n",
       "      <td>59717</td>\n",
       "      <td>283</td>\n",
       "      <td>3.826667</td>\n",
       "      <td>10.324912</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>52.231579</td>\n",
       "      <td>52.392982</td>\n",
       "      <td>0.962267</td>\n",
       "      <td>0.080189</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.148041</td>\n",
       "      <td>0.300708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.0058660170245860566, 0.018968580703150276]</td>\n",
       "      <td>392</td>\n",
       "      <td>14608</td>\n",
       "      <td>6930</td>\n",
       "      <td>68070</td>\n",
       "      <td>74430</td>\n",
       "      <td>570</td>\n",
       "      <td>5.226667</td>\n",
       "      <td>10.251228</td>\n",
       "      <td>12.826667</td>\n",
       "      <td>62.482807</td>\n",
       "      <td>52.392982</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>0.522316</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.01897049757942422, 0.062050812155138114]</td>\n",
       "      <td>555</td>\n",
       "      <td>14445</td>\n",
       "      <td>6538</td>\n",
       "      <td>53462</td>\n",
       "      <td>89038</td>\n",
       "      <td>962</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>10.136842</td>\n",
       "      <td>20.226667</td>\n",
       "      <td>72.619649</td>\n",
       "      <td>52.392982</td>\n",
       "      <td>0.871733</td>\n",
       "      <td>0.108967</td>\n",
       "      <td>0.624828</td>\n",
       "      <td>0.193719</td>\n",
       "      <td>0.363222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.06205176399872563, 0.21779708435772654]</td>\n",
       "      <td>874</td>\n",
       "      <td>14126</td>\n",
       "      <td>5983</td>\n",
       "      <td>39017</td>\n",
       "      <td>103483</td>\n",
       "      <td>1517</td>\n",
       "      <td>11.653333</td>\n",
       "      <td>9.912982</td>\n",
       "      <td>31.880000</td>\n",
       "      <td>82.532632</td>\n",
       "      <td>52.392982</td>\n",
       "      <td>0.797733</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.726196</td>\n",
       "      <td>0.227924</td>\n",
       "      <td>0.398867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.2178099504418494, 0.6708569439895985]</td>\n",
       "      <td>1507</td>\n",
       "      <td>13493</td>\n",
       "      <td>5109</td>\n",
       "      <td>24891</td>\n",
       "      <td>117609</td>\n",
       "      <td>2391</td>\n",
       "      <td>20.093333</td>\n",
       "      <td>9.468772</td>\n",
       "      <td>51.973333</td>\n",
       "      <td>92.001404</td>\n",
       "      <td>52.392982</td>\n",
       "      <td>0.681200</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.825326</td>\n",
       "      <td>0.272480</td>\n",
       "      <td>0.425750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.6710149102313194, 0.999994092188265]</td>\n",
       "      <td>3602</td>\n",
       "      <td>11398</td>\n",
       "      <td>3602</td>\n",
       "      <td>11398</td>\n",
       "      <td>131102</td>\n",
       "      <td>3898</td>\n",
       "      <td>48.026667</td>\n",
       "      <td>7.998596</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>52.392982</td>\n",
       "      <td>0.480267</td>\n",
       "      <td>0.240133</td>\n",
       "      <td>0.920014</td>\n",
       "      <td>0.320178</td>\n",
       "      <td>0.400222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         total                                        faixa_prob  total_um  total_zero    TP      FP      TN    FN    perc_um  perc_zero     csum_um   csum_zero         ks    recall  precision  specificity        F1        F2\n",
       "quantil                                                                                                                                                                                                                          \n",
       "0        15000   [6.252292182237895e-11, 1.5407916538275171e-06]         2       14998  7500  142500       0     0   0.026667  10.524912    0.026667   10.524912  52.392982  1.000000   0.050000     0.000000  0.095238  0.208333\n",
       "1        15000  [1.5411497531130377e-06, 2.8416336743983467e-05]        12       14988  7498  127502   14998     2   0.160000  10.517895    0.186667   21.042807  52.392982  0.999733   0.055541     0.105249  0.105235  0.227212\n",
       "2        15000   [2.8419583485992328e-05, 0.0003183443394388212]        96       14904  7486  112514   29986    14   1.280000  10.458947    1.466667   31.501754  52.392982  0.998133   0.062383     0.210428  0.117427  0.249533\n",
       "3        15000    [0.0003183550525651636, 0.0016153505865386328]       173       14827  7390   97610   44890   110   2.306667  10.404912    3.773333   41.906667  52.392982  0.985333   0.070381     0.315018  0.131378  0.273704\n",
       "4        15000      [0.0016154123547990067, 0.00586593409276533]       287       14713  7217   82783   59717   283   3.826667  10.324912    7.600000   52.231579  52.392982  0.962267   0.080189     0.419067  0.148041  0.300708\n",
       "5        15000     [0.0058660170245860566, 0.018968580703150276]       392       14608  6930   68070   74430   570   5.226667  10.251228   12.826667   62.482807  52.392982  0.924000   0.092400     0.522316  0.168000  0.330000\n",
       "6        15000       [0.01897049757942422, 0.062050812155138114]       555       14445  6538   53462   89038   962   7.400000  10.136842   20.226667   72.619649  52.392982  0.871733   0.108967     0.624828  0.193719  0.363222\n",
       "7        15000        [0.06205176399872563, 0.21779708435772654]       874       14126  5983   39017  103483  1517  11.653333   9.912982   31.880000   82.532632  52.392982  0.797733   0.132956     0.726196  0.227924  0.398867\n",
       "8        15000          [0.2178099504418494, 0.6708569439895985]      1507       13493  5109   24891  117609  2391  20.093333   9.468772   51.973333   92.001404  52.392982  0.681200   0.170300     0.825326  0.272480  0.425750\n",
       "9        15000           [0.6710149102313194, 0.999994092188265]      3602       11398  3602   11398  131102  3898  48.026667   7.998596  100.000000  100.000000  52.392982  0.480267   0.240133     0.920014  0.320178  0.400222"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability = \"probabilty\"\n",
    "label=\"fraude\"\n",
    "quantil=10\n",
    "\n",
    "utils_ml.metric_evaluation(df_2_model, probability, label, quantil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>faixa_prob</th>\n",
       "      <th>total_um</th>\n",
       "      <th>total_zero</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>perc_um</th>\n",
       "      <th>perc_zero</th>\n",
       "      <th>csum_um</th>\n",
       "      <th>csum_zero</th>\n",
       "      <th>ks</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>specificity</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantil</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4500</td>\n",
       "      <td>[2.396255058732618e-10, 1.5855676654949483e-06]</td>\n",
       "      <td>0</td>\n",
       "      <td>4500</td>\n",
       "      <td>2250</td>\n",
       "      <td>42750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>51.415205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4500</td>\n",
       "      <td>[1.5859808027354096e-06, 3.0610923718405375e-05]</td>\n",
       "      <td>3</td>\n",
       "      <td>4497</td>\n",
       "      <td>2250</td>\n",
       "      <td>38250</td>\n",
       "      <td>4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>10.519298</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>21.045614</td>\n",
       "      <td>51.415205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4500</td>\n",
       "      <td>[3.0634114193085304e-05, 0.0003322859025773517]</td>\n",
       "      <td>33</td>\n",
       "      <td>4467</td>\n",
       "      <td>2247</td>\n",
       "      <td>33753</td>\n",
       "      <td>8997</td>\n",
       "      <td>3</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>10.449123</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>31.494737</td>\n",
       "      <td>51.415205</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.062417</td>\n",
       "      <td>0.210456</td>\n",
       "      <td>0.117490</td>\n",
       "      <td>0.249667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.00033239017507906204, 0.0016224921585736903]</td>\n",
       "      <td>59</td>\n",
       "      <td>4441</td>\n",
       "      <td>2214</td>\n",
       "      <td>29286</td>\n",
       "      <td>13464</td>\n",
       "      <td>36</td>\n",
       "      <td>2.622222</td>\n",
       "      <td>10.388304</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>41.883041</td>\n",
       "      <td>51.415205</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.070286</td>\n",
       "      <td>0.314947</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.273333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.0016228355860153402, 0.00591126438191922]</td>\n",
       "      <td>87</td>\n",
       "      <td>4413</td>\n",
       "      <td>2155</td>\n",
       "      <td>24845</td>\n",
       "      <td>17905</td>\n",
       "      <td>95</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>10.322807</td>\n",
       "      <td>8.088889</td>\n",
       "      <td>52.205848</td>\n",
       "      <td>51.415205</td>\n",
       "      <td>0.957778</td>\n",
       "      <td>0.079815</td>\n",
       "      <td>0.418830</td>\n",
       "      <td>0.147350</td>\n",
       "      <td>0.299306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.00591134488850258, 0.018824186141402095]</td>\n",
       "      <td>112</td>\n",
       "      <td>4388</td>\n",
       "      <td>2068</td>\n",
       "      <td>20432</td>\n",
       "      <td>22318</td>\n",
       "      <td>182</td>\n",
       "      <td>4.977778</td>\n",
       "      <td>10.264327</td>\n",
       "      <td>13.066667</td>\n",
       "      <td>62.470175</td>\n",
       "      <td>51.415205</td>\n",
       "      <td>0.919111</td>\n",
       "      <td>0.091911</td>\n",
       "      <td>0.522058</td>\n",
       "      <td>0.167111</td>\n",
       "      <td>0.328254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.01882651708393799, 0.062121204740591976]</td>\n",
       "      <td>182</td>\n",
       "      <td>4318</td>\n",
       "      <td>1956</td>\n",
       "      <td>16044</td>\n",
       "      <td>26706</td>\n",
       "      <td>294</td>\n",
       "      <td>8.088889</td>\n",
       "      <td>10.100585</td>\n",
       "      <td>21.155556</td>\n",
       "      <td>72.570760</td>\n",
       "      <td>51.415205</td>\n",
       "      <td>0.869333</td>\n",
       "      <td>0.108667</td>\n",
       "      <td>0.624702</td>\n",
       "      <td>0.193185</td>\n",
       "      <td>0.362222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.06212566005773768, 0.2154882743177884]</td>\n",
       "      <td>281</td>\n",
       "      <td>4219</td>\n",
       "      <td>1774</td>\n",
       "      <td>11726</td>\n",
       "      <td>31024</td>\n",
       "      <td>476</td>\n",
       "      <td>12.488889</td>\n",
       "      <td>9.869006</td>\n",
       "      <td>33.644444</td>\n",
       "      <td>82.439766</td>\n",
       "      <td>51.415205</td>\n",
       "      <td>0.788444</td>\n",
       "      <td>0.131407</td>\n",
       "      <td>0.725708</td>\n",
       "      <td>0.225270</td>\n",
       "      <td>0.394222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.2155338789449644, 0.6601349375063472]</td>\n",
       "      <td>418</td>\n",
       "      <td>4082</td>\n",
       "      <td>1493</td>\n",
       "      <td>7507</td>\n",
       "      <td>35243</td>\n",
       "      <td>757</td>\n",
       "      <td>18.577778</td>\n",
       "      <td>9.548538</td>\n",
       "      <td>52.222222</td>\n",
       "      <td>91.988304</td>\n",
       "      <td>51.415205</td>\n",
       "      <td>0.663556</td>\n",
       "      <td>0.165889</td>\n",
       "      <td>0.824398</td>\n",
       "      <td>0.265422</td>\n",
       "      <td>0.414722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.6603636563417392, 0.999994092188265]</td>\n",
       "      <td>1075</td>\n",
       "      <td>3425</td>\n",
       "      <td>1075</td>\n",
       "      <td>3425</td>\n",
       "      <td>39325</td>\n",
       "      <td>1175</td>\n",
       "      <td>47.777778</td>\n",
       "      <td>8.011696</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>51.415205</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.238889</td>\n",
       "      <td>0.919883</td>\n",
       "      <td>0.318519</td>\n",
       "      <td>0.398148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         total                                        faixa_prob  total_um  total_zero    TP     FP     TN    FN    perc_um  perc_zero     csum_um   csum_zero         ks    recall  precision  specificity        F1        F2\n",
       "quantil                                                                                                                                                                                                                        \n",
       "0         4500   [2.396255058732618e-10, 1.5855676654949483e-06]         0        4500  2250  42750      0     0   0.000000  10.526316    0.000000   10.526316  51.415205  1.000000   0.050000     0.000000  0.095238  0.208333\n",
       "1         4500  [1.5859808027354096e-06, 3.0610923718405375e-05]         3        4497  2250  38250   4500     0   0.133333  10.519298    0.133333   21.045614  51.415205  1.000000   0.055556     0.105263  0.105263  0.227273\n",
       "2         4500   [3.0634114193085304e-05, 0.0003322859025773517]        33        4467  2247  33753   8997     3   1.466667  10.449123    1.600000   31.494737  51.415205  0.998667   0.062417     0.210456  0.117490  0.249667\n",
       "3         4500   [0.00033239017507906204, 0.0016224921585736903]        59        4441  2214  29286  13464    36   2.622222  10.388304    4.222222   41.883041  51.415205  0.984000   0.070286     0.314947  0.131200  0.273333\n",
       "4         4500      [0.0016228355860153402, 0.00591126438191922]        87        4413  2155  24845  17905    95   3.866667  10.322807    8.088889   52.205848  51.415205  0.957778   0.079815     0.418830  0.147350  0.299306\n",
       "5         4500       [0.00591134488850258, 0.018824186141402095]       112        4388  2068  20432  22318   182   4.977778  10.264327   13.066667   62.470175  51.415205  0.919111   0.091911     0.522058  0.167111  0.328254\n",
       "6         4500       [0.01882651708393799, 0.062121204740591976]       182        4318  1956  16044  26706   294   8.088889  10.100585   21.155556   72.570760  51.415205  0.869333   0.108667     0.624702  0.193185  0.362222\n",
       "7         4500         [0.06212566005773768, 0.2154882743177884]       281        4219  1774  11726  31024   476  12.488889   9.869006   33.644444   82.439766  51.415205  0.788444   0.131407     0.725708  0.225270  0.394222\n",
       "8         4500          [0.2155338789449644, 0.6601349375063472]       418        4082  1493   7507  35243   757  18.577778   9.548538   52.222222   91.988304  51.415205  0.663556   0.165889     0.824398  0.265422  0.414722\n",
       "9         4500           [0.6603636563417392, 0.999994092188265]      1075        3425  1075   3425  39325  1175  47.777778   8.011696  100.000000  100.000000  51.415205  0.477778   0.238889     0.919883  0.318519  0.398148"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame()\n",
    "df_test['fraude'] = y_test\n",
    "df_test['probabilty'] = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "probability = \"probabilty\"\n",
    "label=\"fraude\"\n",
    "quantil=10\n",
    "\n",
    "utils_ml.metric_evaluation(df_test, probability, label, quantil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [x for x in utils_ml.list_subset_words( df.columns.tolist(), ['cat']) if \"WoE\" not in x and \"bin\" not in x and x!='categoria_produto']\n",
    "\n",
    "df_2_model_cat = df[cat_features + [\"fraude\"]]\n",
    "\n",
    "\n",
    "X = df_2_model_cat.drop(['fraude'], axis=1)\n",
    "y = df_2_model_cat['fraude']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=0, stratify=y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cat_def = cb.CatBoostClassifier(\n",
    "                           l2_leaf_reg = 3.0,\n",
    "                           scale_pos_weight = 19,\n",
    "                           verbose=False,\n",
    "                           thread_count = 8,\n",
    "                           random_seed = 0\n",
    "                          )\n",
    "\n",
    "\n",
    "modelo_cat = model_cat_def.fit(X_test , y_test, cat_features =  cat_features  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>categoria_produto_cat</td>\n",
       "      <td>35.340251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o_obj_cat</td>\n",
       "      <td>10.048697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f_float_cat</td>\n",
       "      <td>8.769833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l_float_cat</td>\n",
       "      <td>7.046002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>monto_cat</td>\n",
       "      <td>5.597650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b_float_cat</td>\n",
       "      <td>5.037660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>m_float_cat</td>\n",
       "      <td>4.631854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h_float_cat</td>\n",
       "      <td>4.454312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d_float_cat</td>\n",
       "      <td>3.984561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e_float_cat</td>\n",
       "      <td>3.633807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>k_float_cat</td>\n",
       "      <td>2.639636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pais_cat</td>\n",
       "      <td>2.565475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>p_boolean_cat</td>\n",
       "      <td>2.163730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>c_float_cat</td>\n",
       "      <td>1.821141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a_int_cat</td>\n",
       "      <td>1.732946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>n_boolean_cat</td>\n",
       "      <td>0.532444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 features       coef\n",
       "0   categoria_produto_cat  35.340251\n",
       "1               o_obj_cat  10.048697\n",
       "2             f_float_cat   8.769833\n",
       "3             l_float_cat   7.046002\n",
       "4               monto_cat   5.597650\n",
       "5             b_float_cat   5.037660\n",
       "6             m_float_cat   4.631854\n",
       "7             h_float_cat   4.454312\n",
       "8             d_float_cat   3.984561\n",
       "9             e_float_cat   3.633807\n",
       "10            k_float_cat   2.639636\n",
       "11               pais_cat   2.565475\n",
       "12          p_boolean_cat   2.163730\n",
       "13            c_float_cat   1.821141\n",
       "14              a_int_cat   1.732946\n",
       "15          n_boolean_cat   0.532444"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = pd.DataFrame( {\"features\":modelo_cat.feature_names_,\"coef\":modelo_cat.feature_importances_})\n",
    "coef = coef.sort_values(\"coef\", ascending=False).reset_index(drop=True).query(\"coef>0\")\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9512/240659597.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2_model_cat['probabilty'] = modelo_cat.predict_proba(X)[:,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>faixa_prob</th>\n",
       "      <th>total_um</th>\n",
       "      <th>total_zero</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>perc_um</th>\n",
       "      <th>perc_zero</th>\n",
       "      <th>csum_um</th>\n",
       "      <th>csum_zero</th>\n",
       "      <th>ks</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>specificity</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantil</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>[4.355931477624622e-05, 0.0026637779190214613]</td>\n",
       "      <td>1</td>\n",
       "      <td>14999</td>\n",
       "      <td>7500</td>\n",
       "      <td>142500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>10.525614</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>10.525614</td>\n",
       "      <td>62.807018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.002663785391863515, 0.02154071944650031]</td>\n",
       "      <td>4</td>\n",
       "      <td>14996</td>\n",
       "      <td>7499</td>\n",
       "      <td>127501</td>\n",
       "      <td>14999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>10.523509</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>21.049123</td>\n",
       "      <td>62.807018</td>\n",
       "      <td>0.999867</td>\n",
       "      <td>0.055548</td>\n",
       "      <td>0.105256</td>\n",
       "      <td>0.105249</td>\n",
       "      <td>0.227242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.021546881145244137, 0.07587570182129592]</td>\n",
       "      <td>48</td>\n",
       "      <td>14952</td>\n",
       "      <td>7495</td>\n",
       "      <td>112505</td>\n",
       "      <td>29995</td>\n",
       "      <td>5</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>10.492632</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>31.541754</td>\n",
       "      <td>62.807018</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.062458</td>\n",
       "      <td>0.210491</td>\n",
       "      <td>0.117569</td>\n",
       "      <td>0.249833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.07587752593240998, 0.12026097760608664]</td>\n",
       "      <td>74</td>\n",
       "      <td>14926</td>\n",
       "      <td>7447</td>\n",
       "      <td>97553</td>\n",
       "      <td>44947</td>\n",
       "      <td>53</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>10.474386</td>\n",
       "      <td>1.693333</td>\n",
       "      <td>42.016140</td>\n",
       "      <td>62.807018</td>\n",
       "      <td>0.992933</td>\n",
       "      <td>0.070924</td>\n",
       "      <td>0.315418</td>\n",
       "      <td>0.132391</td>\n",
       "      <td>0.275815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.12026120125156997, 0.16835112282413406]</td>\n",
       "      <td>134</td>\n",
       "      <td>14866</td>\n",
       "      <td>7373</td>\n",
       "      <td>82627</td>\n",
       "      <td>59873</td>\n",
       "      <td>127</td>\n",
       "      <td>1.786667</td>\n",
       "      <td>10.432281</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>52.448421</td>\n",
       "      <td>62.807018</td>\n",
       "      <td>0.983067</td>\n",
       "      <td>0.081922</td>\n",
       "      <td>0.420161</td>\n",
       "      <td>0.151241</td>\n",
       "      <td>0.307208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.16835248566793193, 0.2314909865245594]</td>\n",
       "      <td>224</td>\n",
       "      <td>14776</td>\n",
       "      <td>7239</td>\n",
       "      <td>67761</td>\n",
       "      <td>74739</td>\n",
       "      <td>261</td>\n",
       "      <td>2.986667</td>\n",
       "      <td>10.369123</td>\n",
       "      <td>6.466667</td>\n",
       "      <td>62.817544</td>\n",
       "      <td>62.807018</td>\n",
       "      <td>0.965200</td>\n",
       "      <td>0.096520</td>\n",
       "      <td>0.524484</td>\n",
       "      <td>0.175491</td>\n",
       "      <td>0.344714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.23149464148587984, 0.3327438907942882]</td>\n",
       "      <td>379</td>\n",
       "      <td>14621</td>\n",
       "      <td>7015</td>\n",
       "      <td>52985</td>\n",
       "      <td>89515</td>\n",
       "      <td>485</td>\n",
       "      <td>5.053333</td>\n",
       "      <td>10.260351</td>\n",
       "      <td>11.520000</td>\n",
       "      <td>73.077895</td>\n",
       "      <td>62.807018</td>\n",
       "      <td>0.935333</td>\n",
       "      <td>0.116917</td>\n",
       "      <td>0.628175</td>\n",
       "      <td>0.207852</td>\n",
       "      <td>0.389722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.33274485917061475, 0.48825583608330114]</td>\n",
       "      <td>661</td>\n",
       "      <td>14339</td>\n",
       "      <td>6636</td>\n",
       "      <td>38364</td>\n",
       "      <td>104136</td>\n",
       "      <td>864</td>\n",
       "      <td>8.813333</td>\n",
       "      <td>10.062456</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>83.140351</td>\n",
       "      <td>62.807018</td>\n",
       "      <td>0.884800</td>\n",
       "      <td>0.147467</td>\n",
       "      <td>0.730779</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.442400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.4882570398841099, 0.6842061571004932]</td>\n",
       "      <td>1306</td>\n",
       "      <td>13694</td>\n",
       "      <td>5975</td>\n",
       "      <td>24025</td>\n",
       "      <td>118475</td>\n",
       "      <td>1525</td>\n",
       "      <td>17.413333</td>\n",
       "      <td>9.609825</td>\n",
       "      <td>37.746667</td>\n",
       "      <td>92.750175</td>\n",
       "      <td>62.807018</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.199167</td>\n",
       "      <td>0.831404</td>\n",
       "      <td>0.318667</td>\n",
       "      <td>0.497917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15000</td>\n",
       "      <td>[0.6842352321005802, 0.9990416843309858]</td>\n",
       "      <td>4669</td>\n",
       "      <td>10331</td>\n",
       "      <td>4669</td>\n",
       "      <td>10331</td>\n",
       "      <td>132169</td>\n",
       "      <td>2831</td>\n",
       "      <td>62.253333</td>\n",
       "      <td>7.249825</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>62.807018</td>\n",
       "      <td>0.622533</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.927502</td>\n",
       "      <td>0.415022</td>\n",
       "      <td>0.518778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         total                                      faixa_prob  total_um  total_zero    TP      FP      TN    FN    perc_um  perc_zero     csum_um   csum_zero         ks    recall  precision  specificity        F1        F2\n",
       "quantil                                                                                                                                                                                                                        \n",
       "0        15000  [4.355931477624622e-05, 0.0026637779190214613]         1       14999  7500  142500       0     0   0.013333  10.525614    0.013333   10.525614  62.807018  1.000000   0.050000     0.000000  0.095238  0.208333\n",
       "1        15000     [0.002663785391863515, 0.02154071944650031]         4       14996  7499  127501   14999     1   0.053333  10.523509    0.066667   21.049123  62.807018  0.999867   0.055548     0.105256  0.105249  0.227242\n",
       "2        15000     [0.021546881145244137, 0.07587570182129592]        48       14952  7495  112505   29995     5   0.640000  10.492632    0.706667   31.541754  62.807018  0.999333   0.062458     0.210491  0.117569  0.249833\n",
       "3        15000      [0.07587752593240998, 0.12026097760608664]        74       14926  7447   97553   44947    53   0.986667  10.474386    1.693333   42.016140  62.807018  0.992933   0.070924     0.315418  0.132391  0.275815\n",
       "4        15000      [0.12026120125156997, 0.16835112282413406]       134       14866  7373   82627   59873   127   1.786667  10.432281    3.480000   52.448421  62.807018  0.983067   0.081922     0.420161  0.151241  0.307208\n",
       "5        15000       [0.16835248566793193, 0.2314909865245594]       224       14776  7239   67761   74739   261   2.986667  10.369123    6.466667   62.817544  62.807018  0.965200   0.096520     0.524484  0.175491  0.344714\n",
       "6        15000       [0.23149464148587984, 0.3327438907942882]       379       14621  7015   52985   89515   485   5.053333  10.260351   11.520000   73.077895  62.807018  0.935333   0.116917     0.628175  0.207852  0.389722\n",
       "7        15000      [0.33274485917061475, 0.48825583608330114]       661       14339  6636   38364  104136   864   8.813333  10.062456   20.333333   83.140351  62.807018  0.884800   0.147467     0.730779  0.252800  0.442400\n",
       "8        15000        [0.4882570398841099, 0.6842061571004932]      1306       13694  5975   24025  118475  1525  17.413333   9.609825   37.746667   92.750175  62.807018  0.796667   0.199167     0.831404  0.318667  0.497917\n",
       "9        15000        [0.6842352321005802, 0.9990416843309858]      4669       10331  4669   10331  132169  2831  62.253333   7.249825  100.000000  100.000000  62.807018  0.622533   0.311267     0.927502  0.415022  0.518778"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2_model_cat['probabilty'] = modelo_cat.predict_proba(X)[:,1]\n",
    "\n",
    "probability = \"probabilty\"\n",
    "label=\"fraude\"\n",
    "quantil=10\n",
    "\n",
    "utils_ml.metric_evaluation(df_2_model_cat, probability, label, quantil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>faixa_prob</th>\n",
       "      <th>total_um</th>\n",
       "      <th>total_zero</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>perc_um</th>\n",
       "      <th>perc_zero</th>\n",
       "      <th>csum_um</th>\n",
       "      <th>csum_zero</th>\n",
       "      <th>ks</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>specificity</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantil</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4500</td>\n",
       "      <td>[7.422785450936287e-05, 0.0027188122722824975]</td>\n",
       "      <td>0</td>\n",
       "      <td>4500</td>\n",
       "      <td>2250</td>\n",
       "      <td>42750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>69.660819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.002721314210638236, 0.023845679736645812]</td>\n",
       "      <td>0</td>\n",
       "      <td>4500</td>\n",
       "      <td>2250</td>\n",
       "      <td>38250</td>\n",
       "      <td>4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.052632</td>\n",
       "      <td>69.660819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.023876788079560212, 0.07790472506777066]</td>\n",
       "      <td>0</td>\n",
       "      <td>4500</td>\n",
       "      <td>2250</td>\n",
       "      <td>33750</td>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>69.660819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.07791117030352133, 0.12155999191472747]</td>\n",
       "      <td>2</td>\n",
       "      <td>4498</td>\n",
       "      <td>2250</td>\n",
       "      <td>29250</td>\n",
       "      <td>13500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>10.521637</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>42.100585</td>\n",
       "      <td>69.660819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.12157464458521676, 0.17009555090252354]</td>\n",
       "      <td>11</td>\n",
       "      <td>4489</td>\n",
       "      <td>2248</td>\n",
       "      <td>24752</td>\n",
       "      <td>17998</td>\n",
       "      <td>2</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>10.500585</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>52.601170</td>\n",
       "      <td>69.660819</td>\n",
       "      <td>0.999111</td>\n",
       "      <td>0.083259</td>\n",
       "      <td>0.421006</td>\n",
       "      <td>0.153709</td>\n",
       "      <td>0.312222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.17010144183134931, 0.23242276149566987]</td>\n",
       "      <td>33</td>\n",
       "      <td>4467</td>\n",
       "      <td>2237</td>\n",
       "      <td>20263</td>\n",
       "      <td>22487</td>\n",
       "      <td>13</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>10.449123</td>\n",
       "      <td>2.044444</td>\n",
       "      <td>63.050292</td>\n",
       "      <td>69.660819</td>\n",
       "      <td>0.994222</td>\n",
       "      <td>0.099422</td>\n",
       "      <td>0.526012</td>\n",
       "      <td>0.180768</td>\n",
       "      <td>0.355079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.2324232788380591, 0.33389052420858145]</td>\n",
       "      <td>89</td>\n",
       "      <td>4411</td>\n",
       "      <td>2204</td>\n",
       "      <td>15796</td>\n",
       "      <td>26954</td>\n",
       "      <td>46</td>\n",
       "      <td>3.955556</td>\n",
       "      <td>10.318129</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>73.368421</td>\n",
       "      <td>69.660819</td>\n",
       "      <td>0.979556</td>\n",
       "      <td>0.122444</td>\n",
       "      <td>0.630503</td>\n",
       "      <td>0.217679</td>\n",
       "      <td>0.408148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.33389494787268126, 0.48760192207044845]</td>\n",
       "      <td>176</td>\n",
       "      <td>4324</td>\n",
       "      <td>2115</td>\n",
       "      <td>11385</td>\n",
       "      <td>31365</td>\n",
       "      <td>135</td>\n",
       "      <td>7.822222</td>\n",
       "      <td>10.114620</td>\n",
       "      <td>13.822222</td>\n",
       "      <td>83.483041</td>\n",
       "      <td>69.660819</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.156667</td>\n",
       "      <td>0.733684</td>\n",
       "      <td>0.268571</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.4876033086960946, 0.6836197436951381]</td>\n",
       "      <td>393</td>\n",
       "      <td>4107</td>\n",
       "      <td>1939</td>\n",
       "      <td>7061</td>\n",
       "      <td>35689</td>\n",
       "      <td>311</td>\n",
       "      <td>17.466667</td>\n",
       "      <td>9.607018</td>\n",
       "      <td>31.288889</td>\n",
       "      <td>93.090058</td>\n",
       "      <td>69.660819</td>\n",
       "      <td>0.861778</td>\n",
       "      <td>0.215444</td>\n",
       "      <td>0.834830</td>\n",
       "      <td>0.344711</td>\n",
       "      <td>0.538611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4500</td>\n",
       "      <td>[0.6837212627486914, 0.9986650631885216]</td>\n",
       "      <td>1546</td>\n",
       "      <td>2954</td>\n",
       "      <td>1546</td>\n",
       "      <td>2954</td>\n",
       "      <td>39796</td>\n",
       "      <td>704</td>\n",
       "      <td>68.711111</td>\n",
       "      <td>6.909942</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>69.660819</td>\n",
       "      <td>0.687111</td>\n",
       "      <td>0.343556</td>\n",
       "      <td>0.930901</td>\n",
       "      <td>0.458074</td>\n",
       "      <td>0.572593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         total                                      faixa_prob  total_um  total_zero    TP     FP     TN   FN    perc_um  perc_zero     csum_um   csum_zero         ks    recall  precision  specificity        F1        F2\n",
       "quantil                                                                                                                                                                                                                     \n",
       "0         4500  [7.422785450936287e-05, 0.0027188122722824975]         0        4500  2250  42750      0    0   0.000000  10.526316    0.000000   10.526316  69.660819  1.000000   0.050000     0.000000  0.095238  0.208333\n",
       "1         4500    [0.002721314210638236, 0.023845679736645812]         0        4500  2250  38250   4500    0   0.000000  10.526316    0.000000   21.052632  69.660819  1.000000   0.055556     0.105263  0.105263  0.227273\n",
       "2         4500     [0.023876788079560212, 0.07790472506777066]         0        4500  2250  33750   9000    0   0.000000  10.526316    0.000000   31.578947  69.660819  1.000000   0.062500     0.210526  0.117647  0.250000\n",
       "3         4500      [0.07791117030352133, 0.12155999191472747]         2        4498  2250  29250  13500    0   0.088889  10.521637    0.088889   42.100585  69.660819  1.000000   0.071429     0.315789  0.133333  0.277778\n",
       "4         4500      [0.12157464458521676, 0.17009555090252354]        11        4489  2248  24752  17998    2   0.488889  10.500585    0.577778   52.601170  69.660819  0.999111   0.083259     0.421006  0.153709  0.312222\n",
       "5         4500      [0.17010144183134931, 0.23242276149566987]        33        4467  2237  20263  22487   13   1.466667  10.449123    2.044444   63.050292  69.660819  0.994222   0.099422     0.526012  0.180768  0.355079\n",
       "6         4500       [0.2324232788380591, 0.33389052420858145]        89        4411  2204  15796  26954   46   3.955556  10.318129    6.000000   73.368421  69.660819  0.979556   0.122444     0.630503  0.217679  0.408148\n",
       "7         4500      [0.33389494787268126, 0.48760192207044845]       176        4324  2115  11385  31365  135   7.822222  10.114620   13.822222   83.483041  69.660819  0.940000   0.156667     0.733684  0.268571  0.470000\n",
       "8         4500        [0.4876033086960946, 0.6836197436951381]       393        4107  1939   7061  35689  311  17.466667   9.607018   31.288889   93.090058  69.660819  0.861778   0.215444     0.834830  0.344711  0.538611\n",
       "9         4500        [0.6837212627486914, 0.9986650631885216]      1546        2954  1546   2954  39796  704  68.711111   6.909942  100.000000  100.000000  69.660819  0.687111   0.343556     0.930901  0.458074  0.572593"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame()\n",
    "df_test['fraude'] = y_test\n",
    "df_test['probabilty'] = modelo_cat.predict_proba(X_test)[:,1]\n",
    "\n",
    "probability = \"probabilty\"\n",
    "label=\"fraude\"\n",
    "quantil=10\n",
    "\n",
    "utils_ml.metric_evaluation(df_test, probability, label, quantil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5697.85s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "path_root = parameters.root\n",
    "!pip list --format=freeze > $path_root/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 64-bit ('env_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "f89b9bcb00e7a203e9a9d4cafa46487423203972d974719db00479050a88ae22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
